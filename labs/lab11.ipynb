{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11 - Keras\n",
    "#### Name: Jake Schaeffer\n",
    "#### Class: CSCI 349 - Intro to Data Mining\n",
    "#### Semester: Spring 2020\n",
    "#### Instructor: Brian King"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) What is an artificial neural network (ANN)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computational model that simulates what the brain does by using artificial abstractions of neurons. These perceptrons translate inputs into outputs by aggregating weighted inputs, combining with bias, and putting them into an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) What is deep learning? How does it relate to an ANN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning uses an artificial neural network to \"teach\" how to classify data based on inputs. It does this by updating weights on inputs to perceptrons in order to better represent the boundary between activation and not. By adjusting weights to decrease error, we can make the model better and thus make are classification better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Name a couple of examples where deep learning has made a tremendous impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech recognition - aiding someone that cannot use traditional control methods  \n",
    "Finding anomalies in pictures - like tumors  \n",
    "Identifying objects - like with self driving cars  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Briefly, what is the feedforward algorithm with a neural net?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding inputs through the neural net. The information moves linearly, and weights sareconstantly being updated after every batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) In the context of machine learning, what is a loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function, or error function measures how far off the output from the model is from the actual. We can use the amount of loss to determine the best weights. Less loss = better weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) What is gradient descent? And how is the loss function a critical part of gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at what changes the the inputs of the cost function reduce costs the most, we can figure out what direction we should go with the inputs in order to reduce the cost the most. In other words, gradient descent shows how the cost function will change with different weights and biases. It uses the derivative of the cost function. https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html. So if reducing the bias of input i reduces cost more than increasing it, we should reduce the bais of input i. https://www.analyticsvidhya.com/blog/2017/03/introduction-to-gradient-descent-algorithm-along-its-variants/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Training a neural net involves the backpropagation algorithm. In a few sentences, describe what this algorithm does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation looks at how much the cost changes when the inputs to the cost function are changed. For this, we must be able to average all the cost functions that are functons of the output.\n",
    "http://neuralnetworksanddeeplearning.com/chap2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) What is the difference between batch gradient descent and stochastic gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In batch, all data is used every iteration of the descent. In stochastic, only one piece of data is used for every iteration of the descent.\n",
    "\n",
    "https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) In the context of neural network training, explain the terms epoch and batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch is the data that gets used by the model in one iteration. An epoch is the once we have used all the data in the model. For instance, if we separated the data into 10 batches and used one batch every iteration, we would need to iterate 10 times, each time with a different batch in order to get through one epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) In the context of machine learning, what is a hyperparameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hyperparameter is a parameter that does not change within the model. It is set outside of the model's iterative process.\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-c5619e7e6624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) In the context of neural nets training, what are examples of hyperparameters that can affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate, number of epochs, hidden layers, hidden units, activation functions. https://towardsdatascience.com/understanding-hyperparameters-and-its-optimisation-techniques-f0debba07568"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12) What is an activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An activation function takes in all inputs (bias, weighted inputs) and determines whether the perceptron is activated or not. Typically this is a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13) Most agree that the most popular activation functions are sigmoid, hyperbolic tangent (tanh), softmax, and ReLu (rectified linear unit). Compare and contrast each, using whatever resources you want. Again, 1-2 sentences for each Is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid is 0-1 and differentiable and monotonic. S shaped. slow convergence. saturate and kills gradients.  \n",
    "Hyperbolic tangent is a sigmoid but better. range is -1 to 1.being 0 centered makes it easier to optimized. still kills gradient  \n",
    "Softmax. more generalized logistic activation fuction which is used for multiclass classification. Good for outer layers.  \n",
    "\n",
    "ReLu has 6 times better convergence than tanh. Rectifies vanishing gradient problem. 0 when independent var is <0 and =to independent when >=0  . Most commonly used.  Good for hidden layers.Can result in dead Neurons. \n",
    "  \n",
    "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14) Why is ReLu so popular for large, deep learning networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLu does not Saturate. It doesn't have the vanishing gradient problem. It is also quite cheap to compute converges faster, and is activated sparsely. All of these characteristics are advantageous when dealing with large deep netoworks that have a lot of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15) Why is softmax most appropriate for the output layer, especially for classification problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It limits the output to being between 0 and 1, so that the output can easily be interpreted as a probability. In addition, due to their advantages with multi-class, they are good at combining multiple probabilities together.  \n",
    "https://deepai.org/machine-learning-glossary-and-terms/softmax-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16) What does ReLu sometimes suffer from, and how does a Leaky ReLu activation address it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large weight updates can make th sum of he input into the activation function always be negative. This makes it a dead neuron because it never will activate. In order to avoid this, we can use Leaky Relu, which allows for negative values for when input is a little less than 0.  \n",
    "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17) What is Tensorflow? Who created it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor flow is a library that is centered around neural networks. It was created by the Google Brain team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18) What are tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are generalizations of vectors and matrices. They are represented as n-dimensional arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19) What is keras? Who created it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a neural network library for python. It can run on top of tensorflow. It is a handyh interface that makes it easy to do quick experiments with deep neural networks.\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20) Explain the relationship between keras and tensorflow. How are they similar? Different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras can be built on top of tensorflow. Keras is only highlevel while tensorflow is both high and low level. Keras is specifically for python so it is arguably easier to use than tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21) Describe what the Sequential class represents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a linear stack of layers. These layers can be used for a neural net. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22) What is a layer? How is a layer added to a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Layer connects one tensor to the next. A layer has nodes that can be thought of like neurons. A layer can be added in multiple ways. The simplest would be the add() method of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23) What is a Dense layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dense layer has many nodes. It recieves input from all the previous neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24) What does the compile method do for a model, and what two parameters are required to compile every model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile configures the model for training. And requires an optimizer as well as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) [P] Copy over your code from the previous lab that read in and pre-processed the iris dataset from seaborn. You should have a pandas dataframe that contains four numeric variables and one categorical variable representing the target class. You should have one dataframe X and a dataframe y representing the target class. Do not split your data into training and testing data yet.\n",
    "NORMALLY, I would always expect some EDA tasks to be performed to understand the distributions of your\n",
    "data (i.e. the center, shape, spread of your variables, etc). However, you did a lot of that in the previous lab.\n",
    "Generally, these variables have very similar distributions, with centers that are near each other. Thus,\n",
    "technically, you really don't need to standardize your variables. However, for most models we've learned\n",
    "about, it's a good idea. So, if you did not standardize, go ahead and do that to your X dataframe now using a\n",
    "z-score standardization. (All variables are numeric, so this is quite straightforward.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019004</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.397064</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>-1.283389</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.249201</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>1.448832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>-1.282963</td>\n",
       "      <td>0.705921</td>\n",
       "      <td>0.922303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.795669</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>1.053935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.432165</td>\n",
       "      <td>0.788808</td>\n",
       "      <td>0.933271</td>\n",
       "      <td>1.448832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.068662</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.762758</td>\n",
       "      <td>0.790671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0       -0.900681     1.019004     -1.340227    -1.315444\n",
       "1       -1.143017    -0.131979     -1.340227    -1.315444\n",
       "2       -1.385353     0.328414     -1.397064    -1.315444\n",
       "3       -1.506521     0.098217     -1.283389    -1.315444\n",
       "4       -1.021849     1.249201     -1.340227    -1.315444\n",
       "..            ...          ...           ...          ...\n",
       "145      1.038005    -0.131979      0.819596     1.448832\n",
       "146      0.553333    -1.282963      0.705921     0.922303\n",
       "147      0.795669    -0.131979      0.819596     1.053935\n",
       "148      0.432165     0.788808      0.933271     1.448832\n",
       "149      0.068662    -0.131979      0.762758     0.790671\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.species = pd.Categorical(df_iris.species)\n",
    "X = df_iris.iloc[:,:4]\n",
    "y = pd.DataFrame(df_iris.iloc[:,4])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X),columns = X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) [P] Shuffle your data in your data frames. This will be important for later exercises. Read about the shuffle() function in sklearn.utils. Import it, and use it to shuffle your X and y data frames. Use random_state=0. Remember – it returns the shuffled data! So, be sure to reassign X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X = shuffle(X,random_state = 0)\n",
    "y = shuffle(y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) [P] Use train_test_split to split your data, but this time, let's use an even smaller split, using a 50/50 split, initializing with a random state of 0. (Why? This is a relatively simple dataset. Let's make the problem a bit more challenging by introducing a smaller training data size.) Completing this will result in X_train, X_test, y_train and y_test data frames, both with 75 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .5, train_size = .5,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) [M] How many inputs will your network need to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 because there are 4 variables. (sepal width and length, petal width and length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) [M] Consider the outputs required for a neural network. Remember that the iris dataset is a multi-class dataset. It has to predict three different, categorical values. How do you represent a multi-class target variable in a model like a neural net? For the iris data, what does the final layer of your neural net structure need to look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have 3 possible outputs for the outer layer. And have the target binarized. The final layer needs to have 3 outputs, each representing the probability of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) [P] Write the code to convert the iris target variables (i.e. y_train and y_test) to a set of binarized variables derived from the target class variable (why? Hopefully you figured out why based on your previous answer!)\n",
    "With iris, this means that the \"species\" variable should be converted to a data frame (or numpy\n",
    "array) of three variables, one representing each species. (HINT: as usual, there are many ways to do this. I\n",
    "like pandas get_dummies() or scikit-learn's OneHotEncoder.)\n",
    "OK. You are now going to build a very basic ANN structure with only one hidden layer. Feel free to explore more\n",
    "complex structures, just for practice, but for this simple dataset, you won't need it. For this first exercise, I'll step\n",
    "you through the basics, but you are encouraged to document the &#^!%$ out of each line, as you want to work\n",
    "toward a solid understanding of what you are doing here! Don't just blindly copy and paste what you see online. If\n",
    "you don't document and understand, you will NOT have the guidance and confidence to work through the next\n",
    "assignment. It will be far more challenging.\n",
    "Each line tells you to complete a task. The process is laid out exhaustively to ensure that you understand every\n",
    "critical step toward building the structure of a neural net, train it, and then use it. (HINT: As stated above, be sure\n",
    "to open a page to the Keras documentation referred to above!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_test_unbinarized = y_test.copy()\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Create an instance of Sequential() called model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Now, we will sequentially add layers, starting with the hidden layer that receives the input, then you continue adding layers until you get to the output layer. We will keep it simple: one hidden layer, and one output layer. Add a Dense layer representing the hidden layer. The first layer you add always needs to specify the number of inputs. And, you also need to specify the number of units in the layer (e.g. 9-12 is a good start for these simple data.) Specify an activation function of your choosing. Most basic nets use a 'sigmoid' or 'tanh' activation, though deep learning emphasizes 'relu'. (Be sure you understand why at some point in your near future!) Any of the above is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10,activation = \"tanh\", input_dim = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Add one more layer representing the output layer. Be sure to specify the correct number of outputs.\n",
    "Remember, use a 'softmax' activation here. (NOTE – after you specify your first layer, the number of\n",
    "inputs in further layers added are implied, and thus do not need to be specified.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units  = 3,activation = \"softmax\",input_dim = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) OK. Now compile your model. Look at the documentation for the compile() method. You'll need to specify the following parameters:\n",
    "a) Choose an optimizer  \n",
    "b) Choose the loss function – This is the function that gives you the error that is backpropagated. Use\n",
    "loss='categorical_crossentropy' for this problem.  \n",
    "c) Choose the performance metrics – Typically, you will stick with metrics=['accuracy'] here. You\n",
    "can do far more with your predictions later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) OK, your structure is set. Now you need to train the model.\n",
    "a) epochs = number of epochs to train the model. An epoch is an iteration over all your training data. You\n",
    "will need to experiment. Start with a value of 100.  \n",
    "b) batch_size = number of samples per gradient update. Updating every instance will usually converge\n",
    "the earliest, but with high variance. At the other extreme, batch_size using the entire dataset is slow, but\n",
    "very smooth convergence. Experiment. Use 1, 5, 15. You'll need to select the number of epochs in\n",
    "conjunction with this parameter. For this simple problem, batch_size = 1 will likely work just fine.  \n",
    "c) verbose = 1 will show output as training progresses. Very useful!  \n",
    "d) Use validation_data to pass your test data. This will make it easy to understand if your model is  \n",
    "overfitting your data. (This slows things down a bit more, but it's so important to capture how your model\n",
    "is doing on BOTH training and test data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 1.0248 - accuracy: 0.4133 - val_loss: 0.8355 - val_accuracy: 0.5600\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7233 - accuracy: 0.8000 - val_loss: 0.6642 - val_accuracy: 0.8133\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8533 - val_loss: 0.5770 - val_accuracy: 0.7600\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.9067 - val_loss: 0.5300 - val_accuracy: 0.7733\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.9200 - val_loss: 0.5000 - val_accuracy: 0.7867\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8933 - val_loss: 0.4803 - val_accuracy: 0.8133\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8800 - val_loss: 0.4659 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8800 - val_loss: 0.4521 - val_accuracy: 0.8133\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8933 - val_loss: 0.4404 - val_accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8933 - val_loss: 0.4310 - val_accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8933 - val_loss: 0.4222 - val_accuracy: 0.8133\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8933 - val_loss: 0.4137 - val_accuracy: 0.8267\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8933 - val_loss: 0.4055 - val_accuracy: 0.8267\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8933 - val_loss: 0.4004 - val_accuracy: 0.8267\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.8933 - val_loss: 0.3912 - val_accuracy: 0.8267\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.8933 - val_loss: 0.3834 - val_accuracy: 0.8267\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.8933 - val_loss: 0.3810 - val_accuracy: 0.8267\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.8933 - val_loss: 0.3707 - val_accuracy: 0.8533\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9067 - val_loss: 0.3631 - val_accuracy: 0.8533\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9067 - val_loss: 0.3554 - val_accuracy: 0.8533\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9200 - val_loss: 0.3464 - val_accuracy: 0.8533\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9200 - val_loss: 0.3412 - val_accuracy: 0.8533\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9200 - val_loss: 0.3354 - val_accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9200 - val_loss: 0.3289 - val_accuracy: 0.8533\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9333 - val_loss: 0.3209 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9467 - val_loss: 0.3145 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9467 - val_loss: 0.3104 - val_accuracy: 0.8800\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9467 - val_loss: 0.2990 - val_accuracy: 0.8933\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9467 - val_loss: 0.2953 - val_accuracy: 0.8933\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 0.2864 - val_accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9600 - val_loss: 0.2790 - val_accuracy: 0.8933\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9600 - val_loss: 0.2740 - val_accuracy: 0.8933\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9600 - val_loss: 0.2694 - val_accuracy: 0.9067\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9733 - val_loss: 0.2612 - val_accuracy: 0.9067\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9733 - val_loss: 0.2587 - val_accuracy: 0.9067\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9733 - val_loss: 0.2490 - val_accuracy: 0.9067\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9733 - val_loss: 0.2418 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9733 - val_loss: 0.2377 - val_accuracy: 0.9067\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9733 - val_loss: 0.2329 - val_accuracy: 0.9200\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9733 - val_loss: 0.2263 - val_accuracy: 0.9200\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9867 - val_loss: 0.2251 - val_accuracy: 0.9200\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9733 - val_loss: 0.2193 - val_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9867 - val_loss: 0.2138 - val_accuracy: 0.9333\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9867 - val_loss: 0.2100 - val_accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9867 - val_loss: 0.2047 - val_accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9867 - val_loss: 0.2007 - val_accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9867 - val_loss: 0.1967 - val_accuracy: 0.9333\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9867 - val_loss: 0.1953 - val_accuracy: 0.9333\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9867 - val_loss: 0.1902 - val_accuracy: 0.9333\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9867 - val_loss: 0.1866 - val_accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9867 - val_loss: 0.1847 - val_accuracy: 0.9333\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9867 - val_loss: 0.1805 - val_accuracy: 0.9333\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9867 - val_loss: 0.1769 - val_accuracy: 0.9333\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9867 - val_loss: 0.1763 - val_accuracy: 0.9333\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9867 - val_loss: 0.1729 - val_accuracy: 0.9333\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9867 - val_loss: 0.1707 - val_accuracy: 0.9333\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9867 - val_loss: 0.1678 - val_accuracy: 0.9333\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9867 - val_loss: 0.1652 - val_accuracy: 0.9333\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9867 - val_loss: 0.1641 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9867 - val_loss: 0.1612 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9867 - val_loss: 0.1583 - val_accuracy: 0.9200\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9867 - val_loss: 0.1591 - val_accuracy: 0.9333\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 0.1562 - val_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9867 - val_loss: 0.1538 - val_accuracy: 0.9200\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.1517 - val_accuracy: 0.9200\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.1492 - val_accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9867 - val_loss: 0.1486 - val_accuracy: 0.9200\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.1485 - val_accuracy: 0.9200\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.1464 - val_accuracy: 0.9200\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9867 - val_loss: 0.1451 - val_accuracy: 0.9200\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.1434 - val_accuracy: 0.9200\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.1428 - val_accuracy: 0.9200\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.1412 - val_accuracy: 0.9200\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 0.1392 - val_accuracy: 0.9200\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9867 - val_loss: 0.1387 - val_accuracy: 0.9200\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9867 - val_loss: 0.1377 - val_accuracy: 0.9200\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9867 - val_loss: 0.1375 - val_accuracy: 0.9200\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9867 - val_loss: 0.1361 - val_accuracy: 0.9200\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.1348 - val_accuracy: 0.9200\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 0.1339 - val_accuracy: 0.9200\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.1334 - val_accuracy: 0.9200\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9867 - val_loss: 0.1329 - val_accuracy: 0.9200\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9867 - val_loss: 0.1315 - val_accuracy: 0.9200\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9867 - val_loss: 0.1325 - val_accuracy: 0.9200\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9867 - val_loss: 0.1301 - val_accuracy: 0.9200\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9867 - val_loss: 0.1291 - val_accuracy: 0.9200\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9867 - val_loss: 0.1289 - val_accuracy: 0.9200\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9867 - val_loss: 0.1286 - val_accuracy: 0.9200\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9867 - val_loss: 0.1269 - val_accuracy: 0.9200\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9867 - val_loss: 0.1291 - val_accuracy: 0.9200\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9867 - val_loss: 0.1308 - val_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9867 - val_loss: 0.1265 - val_accuracy: 0.9200\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9867 - val_loss: 0.1259 - val_accuracy: 0.9200\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9867 - val_loss: 0.1266 - val_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9867 - val_loss: 0.1254 - val_accuracy: 0.9333\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9867 - val_loss: 0.1252 - val_accuracy: 0.9333\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9867 - val_loss: 0.1259 - val_accuracy: 0.9333\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9867 - val_loss: 0.1246 - val_accuracy: 0.9333\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9867 - val_loss: 0.1240 - val_accuracy: 0.9333\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9867 - val_loss: 0.1255 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 100, batch_size = 1,verbose = 1, validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12) [P] It's important to understand your accuracy and loss rates as your model proceeds through training. Visualize the loss on training and test data. Look at the code presented here: https://keras.io/visualization/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZyVZf3/8ddnNgaQTTaRRRZxQQFF3DX3DU0s97TSNLI0TdPCb2Wl5dLPSk3STDE101xS0TDNLS1NQSMUUEBSGNYBZJ/lnDmf3x/3PcNhODNzYOaeM3Pu9/PxmAfnvu/r3OdzPw6P63Ou67rv6zJ3R0RE4qsg1wGIiEhuKRGIiMScEoGISMwpEYiIxJwSgYhIzCkRiIjEnBKBxIKZDTYzN7OiLMpeYGb/bI24RNoCJQJpc8zsEzOrNrNe9fbPCCvzwbmJTCQ/KRFIW/U/4NzaDTMbCXTMXThtQzYtGpFtpUQgbdVDwFfStr8KPJhewMy6mdmDZlZuZp+a2Q/NrCA8Vmhmt5rZSjNbAJyc4b33mdlSM1tsZj8zs8JsAjOzx81smZmtNbPXzWyvtGMdzeyXYTxrzeyfZtYxPHaYmb1pZmvMbJGZXRDuf83MLk47xxZdU2Er6FIzmwfMC/fdHp5jnZm9a2aHp5UvNLP/M7OPzWx9eHygmU0ys1/Wu5Znzew72Vy35C8lAmmr/g10NbM9wwr6bOCP9cr8BugGDAWOIEgcF4bHvg6cAuwLjAXOqPfeB4AksGtY5njgYrLzPDAc6AO8BzycduxWYD/gEGBH4HtAyswGhe/7DdAb2AeYkeXnAZwGHAiMCLenhefYEfgT8LiZlYbHriJoTY0DugJfAzaF13xuWrLsBRwDPLINcUg+cnf96a9N/QGfAMcCPwRuAk4E/g4UAQ4MBgqBKmBE2vu+AbwWvn4FuCTt2PHhe4uAvuF7O6YdPxd4NXx9AfDPLGPtHp63G8EPqwpgdIZy1wJPNXCO14CL07a3+Pzw/Ec3EcdntZ8LfASMb6DcHOC48PVlwNRcf9/6y/2f+hulLXsIeB0YQr1uIaAXUAJ8mrbvU6B/+HpnYFG9Y7V2AYqBpWZWu6+gXvmMwtbJz4EzCX7Zp9Li6QCUAh9neOvABvZna4vYzOy7BC2YnQkSRdcwhqY+6wHgfILEej5wezNikjyhriFps9z9U4JB43HAX+odXgkkCCr1WoOAxeHrpQQVYvqxWosIWgS93L17+NfV3feiaV8CxhO0WLoRtE4ALIypEhiW4X2LGtgPsBHolLa9U4YyddMEh+MB3wfOAnq4e3dgbRhDU5/1R2C8mY0G9gSebqCcxIgSgbR1FxF0i2xM3+nuNcBjwM/NrIuZ7ULQN147jvAYcLmZDTCzHsDEtPcuBV4EfmlmXc2swMyGmdkRWcTThSCJrCKovG9MO28KmAz8ysx2DgdtDzazDgTjCMea2VlmVmRmPc1sn/CtM4AvmlknM9s1vOamYkgC5UCRmV1H0CKodS9wg5kNt8AoM+sZxlhGML7wEPCku1dkcc2S55QIpE1z94/dfXoDh79N8Gt6AfBPgkHTyeGx3wMvAP8lGNCt36L4CkHX0myC/vUngH5ZhPQgQTfT4vC9/653/GrgfYLKdjVwC1Dg7gsJWjbfDffPAEaH7/k1UA0sJ+i6eZjGvUAw8Dw3jKWSLbuOfkWQCF8E1gH3seWttw8AIwmSgQjmroVpROLEzD5H0HIaHLZiJObUIhCJETMrBq4A7lUSkFpKBCIxYWZ7AmsIusBuy3E40oaoa0hEJObUIhARibl290BZr169fPDgwbkOQ0SkXXn33XdXunvvTMfaXSIYPHgw06c3dDehiIhkYmafNnQssq4hM5tsZivM7IMGjpuZ3WFm881sppmNiSoWERFpWJRjBH8gmCysIScRzOA4HJgA3BVhLCIi0oDIEoG7v07wBGVDxgMPeuDfQHczy+bJThERaUG5HCPoz5aPxZeF+5Zu64kSiQRlZWVUVla2VGxtXmlpKQMGDKC4uDjXoYhIO5fLRGAZ9mV8qMHMJhB0HzFo0KCtjpeVldGlSxcGDx5M2rTCecvdWbVqFWVlZQwZMiTX4YhIO5fL5wjK2HKa4AHAkkwF3f0edx/r7mN799767qfKykp69uwZiyQAYGb07NkzVi0gEYlOLhPBFOAr4d1DBwFrw+mBt0tckkCtuF2viEQnsq4hM3sEOBLoZWZlwI8JVoXC3e8GphJMyzufYD3VCzOfSWTbLFtbybRPVnPKqH5bJMx1lQke/vdCKqqTOYxOZPsds2dfRg/s3uLnjSwRuPu5TRx34NKoPr81rVq1imOOOQaAZcuWUVhYSG0X1jvvvENJSUmT57jwwguZOHEiu+++e6Sx5rtkTYoJD01nZtlaAD4/eue6Y9f+5X3+OnMpakxJe9Wna2n7SgRx0rNnT2bMmAHAT37yE3bYYQeuvvrqLcrULhJdUJC5N+7++++PPM44+N3rC5hZtpadupZy3TMfcNDQnvTu0oGp7y/lrzOXcs0Ju3PpUbvmOkyRNkWTzkVo/vz57L333lxyySWMGTOGpUuXMmHCBMaOHctee+3F9ddfX1f2sMMOY8aMGSSTSbp3787EiRMZPXo0Bx98MCtWrMjhVbQfHy5bx20vzeXkUf3448UHsLG6hh8+/T6rNlTxo6c/YNSAbnzjc0NzHaZIm5N3LYKfPjuL2UvWteg5R+zclR9/Ppt1zbc2e/Zs7r//fu6++24Abr75ZnbccUeSySRHHXUUZ5xxBiNGjNjiPWvXruWII47g5ptv5qqrrmLy5MlMnDgx0+kllKhJcfXj/6VraTHXn7oXPXfowFXH7cbNz3/I/BUbWF+Z5NYzR1NUqN8+IvXlXSJoa4YNG8b+++9ft/3II49w3333kUwmWbJkCbNnz94qEXTs2JGTTjoJgP3224833nijVWNuLesrE1z0h+ksWLmh2edK1DhrKxLcdd4Yeu7QAYCvHz6Uv32wjBmL1nDNCbuzW98uzf4ckXyUd4lge3+5R6Vz5851r+fNm8ftt9/OO++8Q/fu3Tn//PMzPguQPrhcWFhIMpmfd7ncOPVDpn+6mjP3G0hRYfNHcEfs3JWTRm6epaSwwJh03hief38pFxwyuNnnF8lXeZcI2rJ169bRpUsXunbtytKlS3nhhRc48cTG5uXLX6/PLeeRdxbyjc8N5dpxe0b2Of27d+TiwzUuINIYJYJWNGbMGEaMGMHee+/N0KFDOfTQQ3MdUk6sq0ww8cmZDOvdmSuP2y3X4YjEXrtbs3js2LFef2GaOXPmsOee0f2qbKva2nWnUs5bC1axoarxrqxn/7uEqe8v5clvHsK+g3q0UnQi8WZm77r72EzH1CKQFnPHK/O47aV5WZX91pHDlARE2gglAmkRs5as5c5X5nPyqH5868hhjZbtUFTAsN47tFJkItIUJQJptupkiqsfn0mPziX8/LS96d6p6Sk1RKTtUCKQZrvz1fnMWbqO339lrJKASDukRCANeuXD5Tz41qc0dj+BA2/OX8kX9u3PcSP6tlpsItJylAgko7LPNvHtP/2HLqXF9O1W2mjZo/fow48/P6LRMiLSdikRtICWmIYaYPLkyYwbN46ddtopsliz4e5MfPJ9AB6/5GAG7tgpp/GISLSUCFpANtNQZ2Py5MmMGTMm54ngT+8s5J/zV/Kz0/ZWEhCJASWCiD3wwANMmjSJ6upqDjnkEO68805SqRQXXnghM2bMwN2ZMGECffv2ZcaMGZx99tl07Nhxm1oSLWnR6k3c+Nc5HLprT847cFCrf34k1i+HmupcRxGNwhLokmFsJlEBG1du3u7aHxpYC0O2U0344GRhI9WoO6xbAp5qmc/s2B06tPzkifmXCJ6fCMveb9lz7jQSTrp5m9/2wQcf8NRTT/Hmm29SVFTEhAkTePTRRxk2bBgrV67k/feDONesWUP37t35zW9+w5133sk+++zTsvFnKZVyvv/kTABuOX1UfqyL/K874O8/ynUU0TrmOjj8u5u3N66C330O1pVt3rf7ODjnT2h5thaSrIb7T4LCYvjqcw0ng6nXwLTft9znnvwr2P+iljtfKP8SQRvy0ksvMW3aNMaODZ7qrqioYODAgZxwwgl89NFHXHHFFYwbN47jjz8+x5EGHn5nIW9+vIqff2FvBvTIgy6h5bPh5eth12NhxGm5jiYac56FV2+EXY+DfqOCfVOvhg3L4aRfQHEnWD4L3r4L/vMQjPlKbuPNF2/8EhaHU928eQccftXWZea9FCSBUefA4MNa5nMHHtgy56kn/xLBdvxyj4q787WvfY0bbrhhq2MzZ87k+eef54477uDJJ5/knnvuyUGEmy1avYmbps7h8OG9+NIBedAlVJOAp78Jpd3gC7+Dzr1yHVE09jgZfnsQPP0t+PorMPd5mPUXOPqHcOA3gjKpFCz/AF74AQw7GroNyG3M7d3SmfDGrTDyLKipgtdugt1Pgj5p835VroVnL4fee8Dnb4fixu+8yzV1Gkbo2GOP5bHHHmPlyqCvdtWqVSxcuJDy8nLcnTPPPJOf/vSnvPfeewB06dKF9evXt3qcqZTzvSdmUmDGzXnTJXQbLJ0Bp/wqf5MAQKcd4ZTbYPn78OIP4LmroN8+cOiVm8sUFMD4OyFVA1Mup9EHQ6RxyergB0annnDSLTDul0Gf/dPf3DxmAPDC/8H6ZXDab9t8EoB8bBG0kJQ7qzdW06NTMYXbOcg2cuRIfvzjH3PssceSSqUoLi7m7rvvprCwkIsuugh3x8y45ZZbALjwwgu5+OKLW3Sw+JkZi5m7vPHksmRNJW8tWMVNXxxJ/+4dm/2ZrWb5LPjgya33p5Lw1m9hry/CiPGtH1dr22McjDob3rknGDw+7a6t+6x7DIbjfhp0Gz39LejaL+OppAnlHwWtq3MfDZIwwMm/hMcvgCcvgp7DoGo9/OePcNhV0H+/nIabLU1D3YDl6ypZvq6SnbqV0qdL28zoTV33i7OWMeGhdyksMJr6jT9uZD9uP2ef9tMa2LQ66BLZsAIKCrc+3nNXuGAqdO7Z+rHlwqbV8OB42PfLcOCEzGVSKXjiQvjwudaNLd/s//Wtu6CfuxLee3Dz9sAD4ctPQVGH1o2tEZqGehtVVCdZsa4KgLWbEm02ETTms43V/N9TH7Bnv648c+mhlBTlWS/g3ybCplXwjX9Av9G5jib3Ou0IlzSxtnVBAZz1QOvEEzen/Dr4a6fyrHZovpQ7iz6roLDQ6NOllIpEDVWJmlyHtc1+8uws1myq5tYzR+VfEvhwKsz8c3DLpJKASLPlTQ3RUl1c5eurqEzUMKB7R3bsHPTRr61ItMi5W1Jj1/u3D5bxzIwlfPvo4ey1c7dWjKoVbFoNz30H+o6Ew7f96W0R2VqkXUNmdiJwO1AI3OvuN9c7vgswGegNrAbOd/eyrU7UhNLSUlatWkXPnj2b1cddlaxhxboqenQqoWvHYgA6lRSxtiJBn65tp3vI3Vm1ahWlpUFMi9dUcNEfprFsXSUAG6uS7LVzV751VOMLxOTEhhXwx9Nh7aLte3+yOrhl77wnoEhTXou0hMgSgZkVApOA44AyYJqZTXH32WnFbgUedPcHzOxo4Cbgy9v6WQMGDKCsrIzy8vJmxbypOsnqjQm8awc2LA8aS+srk6ytSFBZ3oGiwrbTgCotLWXAgAHhBHEzWbh6E2fsNwADigsL+OohgyluQ/ECwW2Lz10Z3Hkx5stg2xnfsKM3PzwlIs0WZYvgAGC+uy8AMLNHgfFAeiIYAdTe8Pwq8PT2fFBxcTFDhgxpRqiBW/72Ib9/fRFzbjixrhJdsqaCs25+hWtO2J1Lj9q12Z/R0h55ZyFvzFvJDaftzZcP2iXX4TTu/SeCO1aOuwEOvTzX0YhIKMqfjP2B9PZ/Wbgv3X+B08PXXwC6mNlW9/uZ2QQzm25m05v7q78x85avZ0ivzlv8kt65e0fGDOrOczOXRva522vxmgp+/tc5HDKsJ+e19aeB1y+H56+BAQfAwZfmOhoRSRNliyBTZ339Ec6rgTvN7ALgdWAxkNzqTe73APdA8BxBy4a52bwVG9g7w+DqyaN25obnZrOgfANDG1l0/ZOVG5m9dF1U4W3lwbc+wd255fRRFBS04v3/ySqY//K2zej53oPBjJin/Tbzff8ikjNRJoIyYGDa9gBgSXoBd18CfBHAzHYATnf3tRHG1KCK6hoWrt7EF/at32iBcSN34sapc/jtax9z65mZb1cs+2wTJ9/xBhurW/dW05u+OLL11wx4+puZn+htygk3Qa/hLR+PiDRLlIlgGjDczIYQ/NI/B/hSegEz6wWsdvcUcC3BHUQ58XH5Btxht75bz/Xdr1tHLjliKJNe/ZiTR/bjqD36bHHcffP0zY9fcjBdS4tbJeZOJYWtnwRmPxMkgcOuDCbdylZxR9ix+eM4ItLyIksE7p40s8uAFwhuH53s7rPM7HpgurtPAY4EbjIzJ+gaylnnce18PLv1zdz1c/kxw3lp9gom/mUmL37nCLp12lzZP/z2Qv41P5i+ef/BO7ZKvDmxcWU4qdloOOoHwVzsItLuRXp/obtPdffd3H2Yu/883HddmARw9yfcfXhY5mJ3r4oynsbMXb6B4kJjl56dMx7vUFTIrWeOZuWGaq5/bvONT7XTNx+2a55M39yYqVcH0+uedpeSgEge0VxDofkrtr5jqL6RA7rxrSOH8ZtX5rN4zSaKCgr4dPVGzIybTx/ZfiZsa8zMx2DGw1vvr0nAp/+Co38Effdq/bhEJDJKBKG5yzcwckDT0zF8++jhLF1byf9WbiRRU8NOXUv50ckj8mNFL3d4+QZIVmbuzx/zVTj0O60fl4hESomA4I6hRZ9t4vQxTa/cVFJU0OCdQ+3e4vdg7cKg62efLzVdXkTyQhubgyA35q+ovWOo4WcEYmH2U1BQHCx0LiKxoUTA5juGhsc5EbjDrGeCeXw6ds91NCLSipQICJ4obuyOoVio7Rba67RcRyIirUyJgGCOoaG9dmh7s3W2pll/UbeQSEzFuObbbO6K9eoWmv0M7HqMuoVEYij2iWBTdZJFqysyTi0RG4vfDRaKGaFuIZE4iv3to/NXbABgeJ921iKoScC/boOq9c0/V9m7UFgCu5/U/HOJSLsT+0Qwb3mYCNpbi+DD5+CVn0FhB2iJJ5pHn6NuIZGYin0imLtiPSWFBQzu2c6eDJ71NHTuA9/9UPP7i0izxH6MYN7yDQzt3blNrUfcpOqNMPcFGHGqkoCINFs7qv2iMXf5+vbXLTT3BUhWaHBXRFpErBPBxqokZZ9VtL+B4tlht9Auh+Q6EhHJA7FOBB+XBwPF7WqOoaoNMPdFGDFe3UIi0iJinQjmtsc7huaF3UKaCkJEWkisE8G85cEdQ7u09rq/zTHrKdihLww6ONeRiEieiPXto3OXr2/9O4Y2roIFr27fe91h3t9h3y+rW0hEWkzME8EGxuzSo/U+MFkFfzgZyuc07zyjzmqZeEREiHEi2FiVZPGaCs7Zf2DrfehrNwdJ4Iv3Qr/tXOWsuCN0b8WYRSTvxTYR1M0x1FoDxYvfDeYG2vd8GHVm63ymiEgWYjtYXLsqWavcOpqohKe+CV36wQk3Rv95IiLbIJ4tgtUL2PXtn9K56AwGZXPHULIanvsO7H8R9N9v8/5UCv7+I1j638bfv2k1rPwIzn8SSrs1L3YRkRYWzxbBx6+yb/nTHNN9eXZ3DH38Csx4GJ64KJjnp9a0e+GtO4N9nmr4r2N3OO562PXY6K5JRGQ7RdoiMLMTgduBQuBed7+53vFBwANA97DMRHefGmVMACQrAThghxXZlZ/9NBR1hM/+By9fDyfdAqsXwEs/hl2Pg/Meb5mpoEVEciCyRGBmhcAk4DigDJhmZlPcfXZasR8Cj7n7XWY2ApgKDI4qplrVlRspAUYULWm6cLIKPvwr7H06lHSGt++GPU6B124K1vj9/O1KAiLSrkXZIjgAmO/uCwDM7FFgPJCeCBzoGr7uBmRRMzff6rXr2AkYmPy06cIfvwpV64IpHXY5BOa9CH86CxKbYPwk6NY/8nhFRKIU5RhBf2BR2nZZuC/dT4DzzayMoDXw7QjjqbNufXDHUPcNHzddeNZTUNodhhwRtAjGTwqSwPDjYZ/zIo5URCR6USaCTP0lXm/7XOAP7j4AGAc8ZGZbxWRmE8xsuplNLy8vb3ZgnqgAoHjD4sbX/E1WwUdTg66gopJg3+BD4Ruvw5l/UJeQiOSFKBNBGZD+COwAtu76uQh4DMDd3wJKgV71T+Tu97j7WHcf27t372YHZuFgMQDlcxsu+PErYbfQF7bc32900DoQEckDUSaCacBwMxtiZiXAOcCUemUWAscAmNmeBImg+T/5m1CQrKTKw+GRxub9qe0WGnpE1CGJiORMZInA3ZPAZcALwByCu4Nmmdn1ZnZqWOy7wNfN7L/AI8AF7l6/+6jFFdRU8qn3xYtKYUUDiSBRCR89D3ueAoXFUYckIpIzkT5HED4TMLXevuvSXs8GDo0yhkwKaqrYRCn0Gg7lH2Yu9Pr/C7qFRp/busGJiLSyWD5ZXFhTSRUlWO89YUWGRLD4Pfjnr2H0l2DwYa0foIhIK4pnIkhVUWUdoM8esK4MKtdtPpisgqe/BTv0gRNvyl2QIiKtJJaJoKimkmorgd57BjvKP9p8sHbNgM/fEcwRJCKS52KZCApTVSSsBHrvHuyoHSdY/C7863bY53zY7fjcBSgi0opimQiKU1UkrAP0GAxFpUEiSFSGXUJ94YSf5zpEEZFWE8v1CIpSVSQKOgQLwPfaLbiF9B83BwnhvCfUJSQisRLLRFDsYYsAoM+eweyiC16Ffb8Mw4/LbXAiIq0sfl1DqRTFniBZECaC3ntA9YZwGUl1CYlI/MQvEYTzDNUUholgwP5ghXDqb7SMpIjEUpOJwMwuM7MerRFMqwgTQV2LYMjh8P1PYNdjcheTiEgOZdMi2IlgdbHHzOxEs3Y+93I4BXVNYenmfaVdGygsIpL/mkwE7v5DYDhwH3ABMM/MbjSzYRHHFo2wRZBKTwQiIjGW1RhBOCPosvAvCfQAnjCzX0QYWzQytQhERGKsydtHzexy4KvASuBe4Bp3T4Qric0DvhdtiC1MLQIRkS1k8xxBL+CL7r7FSu/unjKzU6IJK0K1LYIiJQIREciua2gqsLp2w8y6mNmBAO7eyPJebVTtMpVKBCIiQHaJ4C5gQ9r2xnBf+xS2CFxdQyIiQHaJwNKXj3T3FO15aoqwReDFSgQiIpBdIlhgZpebWXH4dwWwIOrAIhO2CCjqmNs4RETaiGwSwSXAIcBioAw4EJgQZVCRClsEVqxEICICWXTxuPsK4JxWiKV1hC0CU9eQiAiQ3XMEpcBFwF5AXe3p7l+LMK7IpBIVQTNILQIRESC7rqGHCOYbOgH4BzAAWB9lUFFKJSqo8iKKi9rveLeISEvKJhHs6u4/Aja6+wPAycDIaMOKTqq6gipKKCmM3wzcIiKZZFMbJsJ/15jZ3kA3YHBkEUXMqyuopITiwvY9iaqISEvJpn/knnA9gh8CU4AdgB9FGlWEPFFBpRdTpBaBiAjQRCIIJ5Zb5+6fAa8DQ7fl5GZ2InA7UAjc6+431zv+a+CocLMT0MfdI105PpUIWgTqGhIRCTSaCMKJ5S4DHtvWE5tZITAJOI7g+YNpZjbF3Wennf/KtPLfBvbd1s/ZZonKoGuoSF1DIiKQ3RjB383sajMbaGY71v5l8b4DgPnuvsDdq4FHgfGNlD8XeCSL8zZPonaMQC0CERHIboyg9nmBS9P2OU13E/UHFqVt1z6VvBUz2wUYArzSwPEJhE8zDxo0qOmIG5OspNKVCEREamXzZPGQ7Tx3pr4Xz7APgieXn3D3mgZiuAe4B2Ds2LENnSO7oJKVVNFRYwQiIqFsniz+Sqb97v5gE28tAwambQ8AljRQ9hy2bHFEJ1lBJV3poUQgIgJk1zW0f9rrUuAY4D2gqUQwDRhuZkMIJqw7B/hS/UJmtjvBGshvZRNwcxXUdQ1psFhEBLLrGvp2+raZdSOYdqKp9yXDO45eILh9dLK7zzKz64Hp7j4lLHou8Gj6mgdRsprau4bUIhARge1bYGYTMDybgu4+lWCpy/R919Xb/sl2xLDdCmqq9ByBiEiabMYInmXzIG8BMILteK6gTXCnMBm0CIrUNSQiAmTXIrg17XUS+NTdyyKKJ1o1CYyUbh8VEUmTTSJYCCx190oAM+toZoPd/ZNII4tCMliUppJidQ2JiISyqQ0fB1Jp2zXhvvYnESxTWaUni0VE6mRTGxaFU0QAEL4uiS6kCNW1CHT7qIhIrWwSQbmZnVq7YWbjgZXRhRShsEVQ6bp9VESkVjZjBJcAD5vZneF2GZDxaeM2L61FoDECEZFANg+UfQwcZGY7AObu7Xa94roWgcYIRETqNFkbmtmNZtbd3Te4+3oz62FmP2uN4Fpc2CKoppjCAo0RiIhAdmMEJ7n7mtqNcLWycdGFFKGwRZAsKM1xICIibUc2iaDQzDrUbphZR6BDI+XbrrBFkCxUIhARqZXNYPEfgZfN7P5w+0LggehCilDYIqgpaJ93v4qIRCGbweJfmNlM4FiCxWb+BuwSdWCRCFsEKbUIRETqZHvrzDKCp4tPJ1iPYE5kEUWptkWgRCAiUqfBFoGZ7UawmMy5wCrgzwS3jx7VSrG1vLBF4EVKBCIitRrrGvoQeAP4vLvPBzCzK1slqqgkKklRgBUW5zoSEZE2o7GuodMJuoReNbPfm9kxZF6Qvv1IVFBtJRQXFeY6EhGRNqPBRODuT7n72cAewGvAlUBfM7vLzI5vpfhaVrKCauugp4pFRNI0WSO6+0Z3f9jdTwEGADOAiZFHFoVEJdWmeYZERNJtU43o7qvd/XfufnRUAUUqWRGsRVDUvnu4RERaUrx+GicqqaKEooJ4XbaISGPiVSPWtgjUNSQiUideNWKiMliLQF1DIiJ14pUIkhVai0BEpJ541YiJSiq9WIlARCRNpDWimZ1oZh+Z2Xwzy3jLqZmdZWazzWyWmf0pynhIVlDhahIE8mIAAAtPSURBVBGIiKTLZhrq7WJmhcAk4DiCdY6nmdkUd5+dVmY4cC1wqLt/ZmZ9oooHgEQlFV5MSaHGCEREakX50/gAYL67L3D3auBRYHy9Ml8HJoWrnuHuKyKMB5KVbFKLQERkC1HWiP2BRWnbZeG+dLsBu5nZv8zs32Z2YoTxQKKCilQxxUVKBCIitSLrGiLzBHWe4fOHA0cSTF/xhpntnb5GMoCZTQAmAAwaNGj7oknVQCrBxpQGi0VE0kVZI5YBA9O2BwBLMpR5xt0T7v4/4COCxLAFd7/H3ce6+9jevXtvXzSJYC2CSko0RiAikibKRDANGG5mQ8yshGCRmyn1yjwNHAVgZr0IuooWRBJNMlidrJISitQiEBGpE1mN6O5J4DLgBYKlLR9z91lmdr2ZnRoWewFYZWazgVeBa9x9VSQBpbUI1DUkIrJZlGMEuPtUYGq9fdelvXbgqvAvWrUtAt0+KiKyhfj8NFaLQEQko/jUiGGLQLOPiohsKT41YnqLQM8RiIjUiU+NWDdGoNtHRUTSxScRaIxARCSj+NSIdc8R6MliEZF08akRa1sEmnRORGQL8akR054sLtYYgYhInfgkAo0RiIhkFJ8a8cBLePXkfygRiIjUE58asaQT60v6AEZJkbqGRERqxScRAMmaFIBaBCIiaWJVIyaUCEREthKrGrG6JlggTYlARGSzWNWIiWTQIihRIhARqROrGrGua0iDxSIideKZCNQiEBGpE6sasXaMoKhALQIRkVqxSgSJmhTFhYaZEoGISK14JYJkSt1CIiL1xKpWDFoEsbpkEZEmxapWTKRciUBEpJ5Y1YqJZErLVIqI1BOvRFCT0sL1IiL1xKpWTNSoa0hEpL5Y1YrVGiwWEdlKpLWimZ1oZh+Z2Xwzm5jh+AVmVm5mM8K/i6OMJ1GjMQIRkfqKojqxmRUCk4DjgDJgmplNcffZ9Yr+2d0viyqOdImaFEVqEYiIbCHKWvEAYL67L3D3auBRYHyEn9ekRNK1cL2ISD1RJoL+wKK07bJwX32nm9lMM3vCzAZmOpGZTTCz6WY2vby8fLsD0hiBiMjWoqwVM/309nrbzwKD3X0U8BLwQKYTufs97j7W3cf27t17uwMKxgiUCERE0kVZK5YB6b/wBwBL0gu4+yp3rwo3fw/sF2E8JHX7qIjIVqKsFacBw81siJmVAOcAU9ILmFm/tM1TgTkRxqMHykREMojsriF3T5rZZcALQCEw2d1nmdn1wHR3nwJcbmanAklgNXBBVPFA7RiBBotFRNJFlggA3H0qMLXevuvSXl8LXBtlDOk0RiAisrVY1YqaYkJEZGuxqhW1MI2IyNZiVStW16QoLtIYgYhIulglgkRNiuKCWF2yiEiTYlMr1qSclKOuIRGRemJTKyZqUgDqGhIRqSd2iUC3j4qIbCk2tWKiJpjmSF1DIiJbik2tWNc1pEQgIrKF2NSK1cnaRKAxAhGRdLFJBHVjBJp0TkRkC7GpFTVGICKSWWxqRY0RiIhkFptasTpMBEUaIxAR2UJsEkEiqecIREQyiU2tqDECEZHMYlMrJlK6fVREJJP4JIKkBotFRDKJTa1Y2zWk5whERLYUm1pRt4+KiGQWm1qxukZjBCIimcQmEWgaahGRzGJTK2qwWEQks9jUirWDxXqyWERkS7FJBIN7dWbcyJ1015CISD2R1opmdqKZfWRm881sYiPlzjAzN7OxUcVy3Ii+/Pa8/ehQVBjVR4iItEuRJQIzKwQmAScBI4BzzWxEhnJdgMuBt6OKRUREGhZli+AAYL67L3D3auBRYHyGcjcAvwAqI4xFREQaEGUi6A8sStsuC/fVMbN9gYHu/lyEcYiISCOiTASZbs/xuoNmBcCvge82eSKzCWY23cyml5eXt2CIIiISZSIoAwambQ8AlqRtdwH2Bl4zs0+Ag4ApmQaM3f0edx/r7mN79+4dYcgiIvETZSKYBgw3syFmVgKcA0ypPejua929l7sPdvfBwL+BU919eoQxiYhIPZElAndPApcBLwBzgMfcfZaZXW9mp0b1uSIism2Kojy5u08Fptbbd10DZY+MMhYREcnM3L3pUm2ImZUDn27n23sBK1swnPYijtcdx2uGeF53HK8Ztv26d3H3jIOs7S4RNIeZTXf3yJ5ebqvieN1xvGaI53XH8ZqhZa9bE++IiMScEoGISMzFLRHck+sAciSO1x3Ha4Z4Xnccrxla8LpjNUYgIiJbi1uLQERE6lEiEBGJudgkgmwXyWnPzGygmb1qZnPMbJaZXRHu39HM/m5m88J/e+Q61pZmZoVm9h8zey7cHmJmb4fX/OdwmpO8YmbdzewJM/sw/M4Pjsl3fWX4//sDM3vEzErz7fs2s8lmtsLMPkjbl/G7tcAdYd0208zGbOvnxSIRZLtITh5IAt919z0JJvG7NLzOicDL7j4ceDnczjdXEExlUusW4NfhNX8GXJSTqKJ1O/A3d98DGE1w/Xn9XZtZf4KFrMa6+95AIcE8Zvn2ff8BOLHevoa+25OA4eHfBOCubf2wWCQCsl8kp11z96Xu/l74ej1BxdCf4FofCIs9AJyWmwijYWYDgJOBe8NtA44GngiL5OM1dwU+B9wH4O7V7r6GPP+uQ0VARzMrAjoBS8mz79vdXwdW19vd0Hc7HnjQA/8GuptZv235vLgkgiYXyck3ZjYY2JdgCdC+7r4UgmQB9MldZJG4DfgekAq3ewJrwokPIT+/76FAOXB/2CV2r5l1Js+/a3dfDNwKLCRIAGuBd8n/7xsa/m6bXb/FJRE0ukhOvjGzHYAnge+4+7pcxxMlMzsFWOHu76bvzlA0377vImAMcJe77wtsJM+6gTIJ+8XHA0OAnYHOBF0j9eXb992YZv9/j0siaGqRnLxhZsUESeBhd/9LuHt5bVMx/HdFruKLwKHAqeHiRo8SdBHcRtA8rp1dNx+/7zKgzN3fDrefIEgM+fxdAxwL/M/dy909AfwFOIT8/76h4e+22fVbXBJBo4vk5Iuwb/w+YI67/yrt0BTgq+HrrwLPtHZsUXH3a919QLi40TnAK+5+HvAqcEZYLK+uGcDdlwGLzGz3cNcxwGzy+LsOLQQOMrNO4f/32uvO6+871NB3OwX4Snj30EHA2toupKy5eyz+gHHAXOBj4Ae5jieiazyMoEk4E5gR/o0j6DN/GZgX/rtjrmON6PqPBJ4LXw8F3gHmA48DHXIdXwTXuw8wPfy+nwZ6xOG7Bn4KfAh8ADwEdMi37xt4hGAMJEHwi/+ihr5bgq6hSWHd9j7BHVXb9HmaYkJEJObi0jUkIiINUCIQEYk5JQIRkZhTIhARiTklAhGRmFMiEKnHzGrMbEbaX4s9sWtmg9NnlBRpC4qaLiISOxXuvk+ugxBpLWoRiGTJzD4xs1vM7J3wb9dw/y5m9nI4F/zLZjYo3N/XzJ4ys/+Gf4eEpyo0s9+Hc+q/aGYdc3ZRIigRiGTSsV7X0Nlpx9a5+wHAnQRzGhG+ftDdRwEPA3eE++8A/uHuownmAZoV7h8OTHL3vYA1wOkRX49Io/RksUg9ZrbB3XfIsP8T4Gh3XxBO7rfM3Xua2Uqgn7snwv1L3b2XmZUDA9y9Ku0cg4G/e7C4CGb2faDY3X8W/ZWJZKYWgci28QZeN1Qmk6q01zVorE5yTIlAZNucnfbvW+HrNwlmPgU4D/hn+Ppl4JtQt6Zy19YKUmRb6JeIyNY6mtmMtO2/uXvtLaQdzOxtgh9R54b7Lgcmm9k1BKuGXRjuvwK4x8wuIvjl/02CGSVF2hSNEYhkKRwjGOvuK3Mdi0hLUteQiEjMqUUgIhJzahGIiMScEoGISMwpEYiIxJwSgYhIzCkRiIjE3P8HM9l+bYP/8IMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotHistory(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plotHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13) Try to change some parameters with the model. However, instead of copying and pasting each individual line you wrote above, follow the approach of creating the entire structure in a single line. \n",
    "Use the example\n",
    "laid out in the Keras documention https://keras.io/getting-started/sequential-model-guide/ This will get\n",
    "you started:\n",
    "model = Sequential([\n",
    "Dense(12, input_shape=(4,)),\n",
    "Activation( ??? ),\n",
    "...\n",
    "])\n",
    "\n",
    "Clearly, you need to finish the rest. And, you'll need to compile and build your model. However, change the\n",
    "parameters in some way from what you did above. Clearly, as given above, you need 4 inputs, and 3\n",
    "outputs. Beyond that, you have countless ways to create a different approach! Different structure? An\n",
    "additional hidden layer? Different activation? Or, use the same structure, and use different batch_size for\n",
    "training? Different optimization algorithm? More epochs? Etc. The choices are quite vast!\n",
    "Generate the same two plots. Compare and contrast your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/150\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 1.3631 - accuracy: 0.2667 - val_loss: 1.1513 - val_accuracy: 0.4000\n",
      "Epoch 2/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 1.3132 - accuracy: 0.2667 - val_loss: 1.1148 - val_accuracy: 0.4267\n",
      "Epoch 3/150\n",
      "75/75 [==============================] - 0s 215us/step - loss: 1.2628 - accuracy: 0.3067 - val_loss: 1.0806 - val_accuracy: 0.4667\n",
      "Epoch 4/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 1.2150 - accuracy: 0.3467 - val_loss: 1.0489 - val_accuracy: 0.5333\n",
      "Epoch 5/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 1.1705 - accuracy: 0.4400 - val_loss: 1.0198 - val_accuracy: 0.5600\n",
      "Epoch 6/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 1.1308 - accuracy: 0.5333 - val_loss: 0.9929 - val_accuracy: 0.6133\n",
      "Epoch 7/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 1.0921 - accuracy: 0.5867 - val_loss: 0.9683 - val_accuracy: 0.6533\n",
      "Epoch 8/150\n",
      "75/75 [==============================] - 0s 313us/step - loss: 1.0574 - accuracy: 0.6267 - val_loss: 0.9452 - val_accuracy: 0.6800\n",
      "Epoch 9/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 1.0236 - accuracy: 0.6267 - val_loss: 0.9236 - val_accuracy: 0.6933\n",
      "Epoch 10/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.9909 - accuracy: 0.6267 - val_loss: 0.9039 - val_accuracy: 0.6933\n",
      "Epoch 11/150\n",
      "75/75 [==============================] - 0s 320us/step - loss: 0.9616 - accuracy: 0.6267 - val_loss: 0.8853 - val_accuracy: 0.6933\n",
      "Epoch 12/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.9355 - accuracy: 0.6267 - val_loss: 0.8675 - val_accuracy: 0.6933\n",
      "Epoch 13/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.9097 - accuracy: 0.6267 - val_loss: 0.8514 - val_accuracy: 0.6933\n",
      "Epoch 14/150\n",
      "75/75 [==============================] - 0s 320us/step - loss: 0.8865 - accuracy: 0.6267 - val_loss: 0.8367 - val_accuracy: 0.6933\n",
      "Epoch 15/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.8630 - accuracy: 0.6267 - val_loss: 0.8233 - val_accuracy: 0.6933\n",
      "Epoch 16/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.8425 - accuracy: 0.6267 - val_loss: 0.8109 - val_accuracy: 0.7067\n",
      "Epoch 17/150\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.8230 - accuracy: 0.6267 - val_loss: 0.7995 - val_accuracy: 0.7067\n",
      "Epoch 18/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.8058 - accuracy: 0.6267 - val_loss: 0.7887 - val_accuracy: 0.7067\n",
      "Epoch 19/150\n",
      "75/75 [==============================] - 0s 386us/step - loss: 0.7882 - accuracy: 0.6267 - val_loss: 0.7785 - val_accuracy: 0.7067\n",
      "Epoch 20/150\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.7725 - accuracy: 0.6267 - val_loss: 0.7689 - val_accuracy: 0.7067\n",
      "Epoch 21/150\n",
      "75/75 [==============================] - 0s 453us/step - loss: 0.7578 - accuracy: 0.6267 - val_loss: 0.7600 - val_accuracy: 0.7067\n",
      "Epoch 22/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.7435 - accuracy: 0.6267 - val_loss: 0.7516 - val_accuracy: 0.7067\n",
      "Epoch 23/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.7300 - accuracy: 0.6267 - val_loss: 0.7434 - val_accuracy: 0.7067\n",
      "Epoch 24/150\n",
      "75/75 [==============================] - 0s 373us/step - loss: 0.7169 - accuracy: 0.6267 - val_loss: 0.7356 - val_accuracy: 0.7067\n",
      "Epoch 25/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.7056 - accuracy: 0.6667 - val_loss: 0.7287 - val_accuracy: 0.7200\n",
      "Epoch 26/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.6935 - accuracy: 0.7333 - val_loss: 0.7218 - val_accuracy: 0.7467\n",
      "Epoch 27/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.6823 - accuracy: 0.7867 - val_loss: 0.7151 - val_accuracy: 0.7600\n",
      "Epoch 28/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.6718 - accuracy: 0.8533 - val_loss: 0.7089 - val_accuracy: 0.7333\n",
      "Epoch 29/150\n",
      "75/75 [==============================] - 0s 452us/step - loss: 0.6616 - accuracy: 0.8800 - val_loss: 0.7028 - val_accuracy: 0.7600\n",
      "Epoch 30/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.6524 - accuracy: 0.8800 - val_loss: 0.6974 - val_accuracy: 0.7733\n",
      "Epoch 31/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.6431 - accuracy: 0.8800 - val_loss: 0.6915 - val_accuracy: 0.7467\n",
      "Epoch 32/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.6346 - accuracy: 0.8800 - val_loss: 0.6856 - val_accuracy: 0.7467\n",
      "Epoch 33/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.6264 - accuracy: 0.8800 - val_loss: 0.6790 - val_accuracy: 0.7600\n",
      "Epoch 34/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.6183 - accuracy: 0.8800 - val_loss: 0.6737 - val_accuracy: 0.7733\n",
      "Epoch 35/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.6102 - accuracy: 0.8667 - val_loss: 0.6682 - val_accuracy: 0.7600\n",
      "Epoch 36/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.6025 - accuracy: 0.8800 - val_loss: 0.6626 - val_accuracy: 0.7600\n",
      "Epoch 37/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.5953 - accuracy: 0.8667 - val_loss: 0.6573 - val_accuracy: 0.7600\n",
      "Epoch 38/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.5877 - accuracy: 0.8800 - val_loss: 0.6513 - val_accuracy: 0.7600\n",
      "Epoch 39/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.5806 - accuracy: 0.8800 - val_loss: 0.6463 - val_accuracy: 0.7867\n",
      "Epoch 40/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.5737 - accuracy: 0.8800 - val_loss: 0.6412 - val_accuracy: 0.7867\n",
      "Epoch 41/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.5668 - accuracy: 0.8800 - val_loss: 0.6361 - val_accuracy: 0.7867\n",
      "Epoch 42/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.5602 - accuracy: 0.8933 - val_loss: 0.6314 - val_accuracy: 0.7733\n",
      "Epoch 43/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.5538 - accuracy: 0.8933 - val_loss: 0.6265 - val_accuracy: 0.7733\n",
      "Epoch 44/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.5473 - accuracy: 0.8933 - val_loss: 0.6221 - val_accuracy: 0.7733\n",
      "Epoch 45/150\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.5416 - accuracy: 0.8933 - val_loss: 0.6183 - val_accuracy: 0.7867\n",
      "Epoch 46/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.5353 - accuracy: 0.8933 - val_loss: 0.6132 - val_accuracy: 0.7733\n",
      "Epoch 47/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.5296 - accuracy: 0.9067 - val_loss: 0.6091 - val_accuracy: 0.7867\n",
      "Epoch 48/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.5235 - accuracy: 0.9067 - val_loss: 0.6042 - val_accuracy: 0.7867\n",
      "Epoch 49/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.5182 - accuracy: 0.9067 - val_loss: 0.5989 - val_accuracy: 0.7867\n",
      "Epoch 50/150\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.5125 - accuracy: 0.9067 - val_loss: 0.5944 - val_accuracy: 0.7867\n",
      "Epoch 51/150\n",
      "75/75 [==============================] - 0s 333us/step - loss: 0.5072 - accuracy: 0.9067 - val_loss: 0.5908 - val_accuracy: 0.7867\n",
      "Epoch 52/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.5019 - accuracy: 0.9067 - val_loss: 0.5853 - val_accuracy: 0.7867\n",
      "Epoch 53/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.4965 - accuracy: 0.9067 - val_loss: 0.5809 - val_accuracy: 0.7867\n",
      "Epoch 54/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.4915 - accuracy: 0.9067 - val_loss: 0.5757 - val_accuracy: 0.7867\n",
      "Epoch 55/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.4864 - accuracy: 0.8933 - val_loss: 0.5716 - val_accuracy: 0.7867\n",
      "Epoch 56/150\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.4814 - accuracy: 0.8933 - val_loss: 0.5673 - val_accuracy: 0.7867\n",
      "Epoch 57/150\n",
      "75/75 [==============================] - 0s 333us/step - loss: 0.4767 - accuracy: 0.8933 - val_loss: 0.5633 - val_accuracy: 0.7867\n",
      "Epoch 58/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.4725 - accuracy: 0.8933 - val_loss: 0.5576 - val_accuracy: 0.8000\n",
      "Epoch 59/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.4673 - accuracy: 0.8933 - val_loss: 0.5537 - val_accuracy: 0.8000\n",
      "Epoch 60/150\n",
      "75/75 [==============================] - 0s 292us/step - loss: 0.4628 - accuracy: 0.8933 - val_loss: 0.5497 - val_accuracy: 0.7867\n",
      "Epoch 61/150\n",
      "75/75 [==============================] - 0s 364us/step - loss: 0.4583 - accuracy: 0.8933 - val_loss: 0.5459 - val_accuracy: 0.7867\n",
      "Epoch 62/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.4540 - accuracy: 0.8933 - val_loss: 0.5436 - val_accuracy: 0.8000\n",
      "Epoch 63/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.4496 - accuracy: 0.8933 - val_loss: 0.5398 - val_accuracy: 0.8000\n",
      "Epoch 64/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.4453 - accuracy: 0.8933 - val_loss: 0.5370 - val_accuracy: 0.8000\n",
      "Epoch 65/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.4414 - accuracy: 0.8933 - val_loss: 0.5340 - val_accuracy: 0.8000\n",
      "Epoch 66/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.4372 - accuracy: 0.8933 - val_loss: 0.5311 - val_accuracy: 0.8000\n",
      "Epoch 67/150\n",
      "75/75 [==============================] - 0s 294us/step - loss: 0.4332 - accuracy: 0.8933 - val_loss: 0.5269 - val_accuracy: 0.7867\n",
      "Epoch 68/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.4293 - accuracy: 0.8933 - val_loss: 0.5237 - val_accuracy: 0.7867\n",
      "Epoch 69/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.4255 - accuracy: 0.8933 - val_loss: 0.5210 - val_accuracy: 0.7867\n",
      "Epoch 70/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.4215 - accuracy: 0.9067 - val_loss: 0.5179 - val_accuracy: 0.7867\n",
      "Epoch 71/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.4179 - accuracy: 0.9067 - val_loss: 0.5147 - val_accuracy: 0.7867\n",
      "Epoch 72/150\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.4143 - accuracy: 0.9067 - val_loss: 0.5117 - val_accuracy: 0.7867\n",
      "Epoch 73/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.4105 - accuracy: 0.9067 - val_loss: 0.5097 - val_accuracy: 0.7867\n",
      "Epoch 74/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.4070 - accuracy: 0.9067 - val_loss: 0.5075 - val_accuracy: 0.7867\n",
      "Epoch 75/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.4035 - accuracy: 0.9067 - val_loss: 0.5046 - val_accuracy: 0.7867\n",
      "Epoch 76/150\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.4001 - accuracy: 0.9067 - val_loss: 0.5014 - val_accuracy: 0.7867\n",
      "Epoch 77/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.3967 - accuracy: 0.9067 - val_loss: 0.4996 - val_accuracy: 0.7867\n",
      "Epoch 78/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3933 - accuracy: 0.9067 - val_loss: 0.4972 - val_accuracy: 0.7867\n",
      "Epoch 79/150\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.3901 - accuracy: 0.9067 - val_loss: 0.4948 - val_accuracy: 0.7867\n",
      "Epoch 80/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3867 - accuracy: 0.9067 - val_loss: 0.4924 - val_accuracy: 0.7867\n",
      "Epoch 81/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.3839 - accuracy: 0.9067 - val_loss: 0.4905 - val_accuracy: 0.7867\n",
      "Epoch 82/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.3808 - accuracy: 0.9067 - val_loss: 0.4868 - val_accuracy: 0.7867\n",
      "Epoch 83/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3775 - accuracy: 0.9067 - val_loss: 0.4844 - val_accuracy: 0.7867\n",
      "Epoch 84/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.3748 - accuracy: 0.9067 - val_loss: 0.4814 - val_accuracy: 0.7867\n",
      "Epoch 85/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.3717 - accuracy: 0.9067 - val_loss: 0.4786 - val_accuracy: 0.7867\n",
      "Epoch 86/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.3688 - accuracy: 0.9067 - val_loss: 0.4768 - val_accuracy: 0.7867\n",
      "Epoch 87/150\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.3659 - accuracy: 0.9067 - val_loss: 0.4744 - val_accuracy: 0.7867\n",
      "Epoch 88/150\n",
      "75/75 [==============================] - 0s 439us/step - loss: 0.3632 - accuracy: 0.9200 - val_loss: 0.4717 - val_accuracy: 0.7733\n",
      "Epoch 89/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.3605 - accuracy: 0.9200 - val_loss: 0.4694 - val_accuracy: 0.7600\n",
      "Epoch 90/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.3577 - accuracy: 0.9200 - val_loss: 0.4683 - val_accuracy: 0.7867\n",
      "Epoch 91/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.3551 - accuracy: 0.9200 - val_loss: 0.4667 - val_accuracy: 0.7867\n",
      "Epoch 92/150\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.3524 - accuracy: 0.9200 - val_loss: 0.4648 - val_accuracy: 0.7867\n",
      "Epoch 93/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.3500 - accuracy: 0.9200 - val_loss: 0.4632 - val_accuracy: 0.7867\n",
      "Epoch 94/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.3473 - accuracy: 0.9200 - val_loss: 0.4608 - val_accuracy: 0.7867\n",
      "Epoch 95/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3449 - accuracy: 0.9200 - val_loss: 0.4586 - val_accuracy: 0.7733\n",
      "Epoch 96/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.3422 - accuracy: 0.9200 - val_loss: 0.4576 - val_accuracy: 0.7867\n",
      "Epoch 97/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.3398 - accuracy: 0.9200 - val_loss: 0.4562 - val_accuracy: 0.7867\n",
      "Epoch 98/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.3374 - accuracy: 0.9200 - val_loss: 0.4548 - val_accuracy: 0.7867\n",
      "Epoch 99/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3349 - accuracy: 0.9200 - val_loss: 0.4538 - val_accuracy: 0.7867\n",
      "Epoch 100/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.3329 - accuracy: 0.9200 - val_loss: 0.4530 - val_accuracy: 0.7867\n",
      "Epoch 101/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.3303 - accuracy: 0.9200 - val_loss: 0.4512 - val_accuracy: 0.7867\n",
      "Epoch 102/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.3280 - accuracy: 0.9200 - val_loss: 0.4496 - val_accuracy: 0.7867\n",
      "Epoch 103/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.3256 - accuracy: 0.9200 - val_loss: 0.4474 - val_accuracy: 0.7867\n",
      "Epoch 104/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.3234 - accuracy: 0.9200 - val_loss: 0.4445 - val_accuracy: 0.7733\n",
      "Epoch 105/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.3214 - accuracy: 0.9200 - val_loss: 0.4415 - val_accuracy: 0.7733\n",
      "Epoch 106/150\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.3193 - accuracy: 0.9200 - val_loss: 0.4387 - val_accuracy: 0.7733\n",
      "Epoch 107/150\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.3171 - accuracy: 0.9200 - val_loss: 0.4374 - val_accuracy: 0.7733\n",
      "Epoch 108/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.3149 - accuracy: 0.9200 - val_loss: 0.4350 - val_accuracy: 0.7733\n",
      "Epoch 109/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.3129 - accuracy: 0.9200 - val_loss: 0.4333 - val_accuracy: 0.7733\n",
      "Epoch 110/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.3108 - accuracy: 0.9200 - val_loss: 0.4326 - val_accuracy: 0.7733\n",
      "Epoch 111/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3088 - accuracy: 0.9200 - val_loss: 0.4315 - val_accuracy: 0.7733\n",
      "Epoch 112/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.3068 - accuracy: 0.9200 - val_loss: 0.4301 - val_accuracy: 0.7733\n",
      "Epoch 113/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.3048 - accuracy: 0.9200 - val_loss: 0.4293 - val_accuracy: 0.7733\n",
      "Epoch 114/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.3033 - accuracy: 0.9200 - val_loss: 0.4289 - val_accuracy: 0.7867\n",
      "Epoch 115/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.3010 - accuracy: 0.9200 - val_loss: 0.4263 - val_accuracy: 0.7733\n",
      "Epoch 116/150\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.2990 - accuracy: 0.9200 - val_loss: 0.4256 - val_accuracy: 0.7867\n",
      "Epoch 117/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.2970 - accuracy: 0.9200 - val_loss: 0.4240 - val_accuracy: 0.7733\n",
      "Epoch 118/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.2953 - accuracy: 0.9200 - val_loss: 0.4222 - val_accuracy: 0.7733\n",
      "Epoch 119/150\n",
      "75/75 [==============================] - 0s 505us/step - loss: 0.2934 - accuracy: 0.9200 - val_loss: 0.4205 - val_accuracy: 0.7733\n",
      "Epoch 120/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.2917 - accuracy: 0.9200 - val_loss: 0.4194 - val_accuracy: 0.7733\n",
      "Epoch 121/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.2899 - accuracy: 0.9200 - val_loss: 0.4179 - val_accuracy: 0.7733\n",
      "Epoch 122/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.2883 - accuracy: 0.9200 - val_loss: 0.4179 - val_accuracy: 0.7867\n",
      "Epoch 123/150\n",
      "75/75 [==============================] - 0s 386us/step - loss: 0.2864 - accuracy: 0.9200 - val_loss: 0.4168 - val_accuracy: 0.7867\n",
      "Epoch 124/150\n",
      "75/75 [==============================] - 0s 292us/step - loss: 0.2850 - accuracy: 0.9200 - val_loss: 0.4142 - val_accuracy: 0.7733\n",
      "Epoch 125/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.2830 - accuracy: 0.9200 - val_loss: 0.4130 - val_accuracy: 0.7733\n",
      "Epoch 126/150\n",
      "75/75 [==============================] - 0s 252us/step - loss: 0.2813 - accuracy: 0.9200 - val_loss: 0.4121 - val_accuracy: 0.7733\n",
      "Epoch 127/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.2796 - accuracy: 0.9200 - val_loss: 0.4109 - val_accuracy: 0.7733\n",
      "Epoch 128/150\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.2779 - accuracy: 0.9200 - val_loss: 0.4102 - val_accuracy: 0.7867\n",
      "Epoch 129/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.2763 - accuracy: 0.9200 - val_loss: 0.4092 - val_accuracy: 0.7867\n",
      "Epoch 130/150\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.2747 - accuracy: 0.9200 - val_loss: 0.4088 - val_accuracy: 0.7867\n",
      "Epoch 131/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.2730 - accuracy: 0.9200 - val_loss: 0.4076 - val_accuracy: 0.7867\n",
      "Epoch 132/150\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.2715 - accuracy: 0.9200 - val_loss: 0.4058 - val_accuracy: 0.7867\n",
      "Epoch 133/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.2698 - accuracy: 0.9200 - val_loss: 0.4048 - val_accuracy: 0.7867\n",
      "Epoch 134/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.2686 - accuracy: 0.9200 - val_loss: 0.4048 - val_accuracy: 0.7867\n",
      "Epoch 135/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.2668 - accuracy: 0.9200 - val_loss: 0.4036 - val_accuracy: 0.7867\n",
      "Epoch 136/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.2653 - accuracy: 0.9200 - val_loss: 0.4025 - val_accuracy: 0.7867\n",
      "Epoch 137/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.2641 - accuracy: 0.9200 - val_loss: 0.4027 - val_accuracy: 0.7867\n",
      "Epoch 138/150\n",
      "75/75 [==============================] - 0s 603us/step - loss: 0.2623 - accuracy: 0.9200 - val_loss: 0.4009 - val_accuracy: 0.7867\n",
      "Epoch 139/150\n",
      "75/75 [==============================] - 0s 398us/step - loss: 0.2609 - accuracy: 0.9200 - val_loss: 0.3995 - val_accuracy: 0.7867\n",
      "Epoch 140/150\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.2595 - accuracy: 0.9200 - val_loss: 0.3980 - val_accuracy: 0.7867\n",
      "Epoch 141/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.2581 - accuracy: 0.9200 - val_loss: 0.3978 - val_accuracy: 0.7867\n",
      "Epoch 142/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.2567 - accuracy: 0.9200 - val_loss: 0.3972 - val_accuracy: 0.8000\n",
      "Epoch 143/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.2552 - accuracy: 0.9200 - val_loss: 0.3958 - val_accuracy: 0.8000\n",
      "Epoch 144/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.2538 - accuracy: 0.9333 - val_loss: 0.3956 - val_accuracy: 0.8000\n",
      "Epoch 145/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.2524 - accuracy: 0.9333 - val_loss: 0.3936 - val_accuracy: 0.8000\n",
      "Epoch 146/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.2509 - accuracy: 0.9333 - val_loss: 0.3926 - val_accuracy: 0.8000\n",
      "Epoch 147/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.2496 - accuracy: 0.9333 - val_loss: 0.3908 - val_accuracy: 0.7867\n",
      "Epoch 148/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.2483 - accuracy: 0.9333 - val_loss: 0.3902 - val_accuracy: 0.8000\n",
      "Epoch 149/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.2469 - accuracy: 0.9333 - val_loss: 0.3899 - val_accuracy: 0.8000\n",
      "Epoch 150/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.2454 - accuracy: 0.9467 - val_loss: 0.3887 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([Dense(12,input_shape = (4,)),Activation(\"sigmoid\"),Dense(units = 3,input_shape=(12,)),Activation(\"softmax\")])\n",
    "model.compile(optimizer = \"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n",
    "history = model.fit(X_train,y_train,epochs = 150, batch_size = 10,verbose = 1, validation_data = (X_test,y_test))\n",
    "plotHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the hidden layer from tanh to sigmoid, epochs from 100 to 150, and batch size from 1 to 10. I noticed that it took less epochs to get to 100% accuracy but then as the epochs continue the accuracy actually goes down. This is likely because I use a sigmoid activation function, which experienced gradient decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14) OK, one more time. This time, copy the same model, but use an SGD optimizer. \n",
    "Of course, you may have\n",
    "already chosen this by specifying the optimizer='sgd' parameter when you compiled your model. This\n",
    "time, you will instantiate your optimizer.\n",
    "From Keras documentation:\n",
    "\n",
    "Copy one of your models above. (Remember, if you keep using the same model instance, you are\n",
    "continually improving the weights, and thus not evaluating your new model properly! When you\n",
    "experiment with new models, you need to instantiate a new model, or figure out how to reset your\n",
    "weights to random initial values. For now, it's just easy enough to reinstantiate a new model.)\n",
    "Now, instantiate SGD. Look at the documentation, and choose a different learning rate (lr) and a\n",
    "momentum value of some value between 0.5-0.9. Compile and fit your model. Regenerate your accuracy\n",
    "and loss plots. Compare and contrast your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/150\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.9668 - accuracy: 0.4933 - val_loss: 0.6988 - val_accuracy: 0.6400\n",
      "Epoch 2/150\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.5070 - accuracy: 0.8267 - val_loss: 0.4444 - val_accuracy: 0.8133\n",
      "Epoch 3/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.2964 - accuracy: 0.9200 - val_loss: 0.4420 - val_accuracy: 0.8000\n",
      "Epoch 4/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.2526 - accuracy: 0.9067 - val_loss: 0.3413 - val_accuracy: 0.8533\n",
      "Epoch 5/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.2063 - accuracy: 0.9333 - val_loss: 0.3364 - val_accuracy: 0.8533\n",
      "Epoch 6/150\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.1752 - accuracy: 0.9467 - val_loss: 0.3167 - val_accuracy: 0.8533\n",
      "Epoch 7/150\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.1646 - accuracy: 0.9467 - val_loss: 0.3030 - val_accuracy: 0.8933\n",
      "Epoch 8/150\n",
      "75/75 [==============================] - 0s 412us/step - loss: 0.1385 - accuracy: 0.9733 - val_loss: 0.3093 - val_accuracy: 0.8267\n",
      "Epoch 9/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.1311 - accuracy: 0.9600 - val_loss: 0.2844 - val_accuracy: 0.9067\n",
      "Epoch 10/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1145 - accuracy: 0.9733 - val_loss: 0.2551 - val_accuracy: 0.9467\n",
      "Epoch 11/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.1019 - accuracy: 0.9733 - val_loss: 0.2481 - val_accuracy: 0.9333\n",
      "Epoch 12/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0971 - accuracy: 0.9733 - val_loss: 0.2260 - val_accuracy: 0.9333\n",
      "Epoch 13/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.0837 - accuracy: 0.9867 - val_loss: 0.2101 - val_accuracy: 0.9467\n",
      "Epoch 14/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0817 - accuracy: 0.9867 - val_loss: 0.2004 - val_accuracy: 0.9467\n",
      "Epoch 15/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0801 - accuracy: 0.9733 - val_loss: 0.1962 - val_accuracy: 0.9467\n",
      "Epoch 16/150\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0704 - accuracy: 0.9867 - val_loss: 0.1919 - val_accuracy: 0.9467\n",
      "Epoch 17/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0651 - accuracy: 0.9867 - val_loss: 0.1766 - val_accuracy: 0.9467\n",
      "Epoch 18/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0608 - accuracy: 0.9867 - val_loss: 0.1660 - val_accuracy: 0.9333\n",
      "Epoch 19/150\n",
      "75/75 [==============================] - 0s 439us/step - loss: 0.0574 - accuracy: 0.9867 - val_loss: 0.1686 - val_accuracy: 0.9333\n",
      "Epoch 20/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0540 - accuracy: 0.9867 - val_loss: 0.1591 - val_accuracy: 0.9333\n",
      "Epoch 21/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0567 - accuracy: 0.9867 - val_loss: 0.1544 - val_accuracy: 0.9333\n",
      "Epoch 22/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9333\n",
      "Epoch 23/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0499 - accuracy: 0.9867 - val_loss: 0.1457 - val_accuracy: 0.9333\n",
      "Epoch 24/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.1429 - val_accuracy: 0.9333\n",
      "Epoch 25/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 0.1383 - val_accuracy: 0.9333\n",
      "Epoch 26/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.1368 - val_accuracy: 0.9333\n",
      "Epoch 27/150\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 0.1360 - val_accuracy: 0.9333\n",
      "Epoch 28/150\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.1385 - val_accuracy: 0.9333\n",
      "Epoch 29/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.0423 - accuracy: 0.9867 - val_loss: 0.1293 - val_accuracy: 0.9333\n",
      "Epoch 30/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0372 - accuracy: 0.9867 - val_loss: 0.1289 - val_accuracy: 0.9333\n",
      "Epoch 31/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 0.1277 - val_accuracy: 0.9333\n",
      "Epoch 32/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.1261 - val_accuracy: 0.9333\n",
      "Epoch 33/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0357 - accuracy: 0.9867 - val_loss: 0.1219 - val_accuracy: 0.9333\n",
      "Epoch 34/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0327 - accuracy: 0.9867 - val_loss: 0.1214 - val_accuracy: 0.9333\n",
      "Epoch 35/150\n",
      "75/75 [==============================] - 0s 201us/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 0.1200 - val_accuracy: 0.9333\n",
      "Epoch 36/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0331 - accuracy: 0.9867 - val_loss: 0.1194 - val_accuracy: 0.9333\n",
      "Epoch 37/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0326 - accuracy: 0.9867 - val_loss: 0.1187 - val_accuracy: 0.9333\n",
      "Epoch 38/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0346 - accuracy: 0.9867 - val_loss: 0.1195 - val_accuracy: 0.9467\n",
      "Epoch 39/150\n",
      "75/75 [==============================] - 0s 240us/step - loss: 0.0283 - accuracy: 0.9867 - val_loss: 0.1164 - val_accuracy: 0.9333\n",
      "Epoch 40/150\n",
      "75/75 [==============================] - 0s 242us/step - loss: 0.0303 - accuracy: 0.9867 - val_loss: 0.1187 - val_accuracy: 0.9333\n",
      "Epoch 41/150\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0287 - accuracy: 0.9867 - val_loss: 0.1198 - val_accuracy: 0.9467\n",
      "Epoch 42/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0280 - accuracy: 0.9867 - val_loss: 0.1197 - val_accuracy: 0.9467\n",
      "Epoch 43/150\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9467\n",
      "Epoch 44/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0277 - accuracy: 0.9867 - val_loss: 0.1189 - val_accuracy: 0.9333\n",
      "Epoch 45/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0261 - accuracy: 0.9867 - val_loss: 0.1179 - val_accuracy: 0.9333\n",
      "Epoch 46/150\n",
      "75/75 [==============================] - 0s 263us/step - loss: 0.0279 - accuracy: 0.9867 - val_loss: 0.1167 - val_accuracy: 0.9333\n",
      "Epoch 47/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0284 - accuracy: 0.9867 - val_loss: 0.1135 - val_accuracy: 0.9333\n",
      "Epoch 48/150\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0243 - accuracy: 0.9867 - val_loss: 0.1176 - val_accuracy: 0.9600\n",
      "Epoch 49/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9600\n",
      "Epoch 50/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0239 - accuracy: 0.9867 - val_loss: 0.1139 - val_accuracy: 0.9333\n",
      "Epoch 51/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.0235 - accuracy: 0.9867 - val_loss: 0.1164 - val_accuracy: 0.9600\n",
      "Epoch 52/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9600\n",
      "Epoch 53/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
      "Epoch 54/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9600\n",
      "Epoch 55/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9600\n",
      "Epoch 56/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9333\n",
      "Epoch 57/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0236 - accuracy: 0.9867 - val_loss: 0.1087 - val_accuracy: 0.9333\n",
      "Epoch 58/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9467\n",
      "Epoch 59/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9600\n",
      "Epoch 60/150\n",
      "75/75 [==============================] - 0s 333us/step - loss: 0.0218 - accuracy: 0.9867 - val_loss: 0.1091 - val_accuracy: 0.9333\n",
      "Epoch 61/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0240 - accuracy: 0.9867 - val_loss: 0.1175 - val_accuracy: 0.9600\n",
      "Epoch 62/150\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9600\n",
      "Epoch 63/150\n",
      "75/75 [==============================] - 0s 216us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9467\n",
      "Epoch 64/150\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.0209 - accuracy: 0.9867 - val_loss: 0.1060 - val_accuracy: 0.9600\n",
      "Epoch 65/150\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9600\n",
      "Epoch 66/150\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9600\n",
      "Epoch 67/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9600\n",
      "Epoch 68/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9600\n",
      "Epoch 69/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9600\n",
      "Epoch 70/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
      "Epoch 71/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9600\n",
      "Epoch 72/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0190 - accuracy: 0.9867 - val_loss: 0.1023 - val_accuracy: 0.9600\n",
      "Epoch 73/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9467\n",
      "Epoch 74/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9467\n",
      "Epoch 75/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9600\n",
      "Epoch 76/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0180 - accuracy: 0.9867 - val_loss: 0.1065 - val_accuracy: 0.9600\n",
      "Epoch 77/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9600\n",
      "Epoch 78/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9600\n",
      "Epoch 79/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9600\n",
      "Epoch 80/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9600\n",
      "Epoch 81/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9600\n",
      "Epoch 82/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9600\n",
      "Epoch 83/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9600\n",
      "Epoch 84/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9600\n",
      "Epoch 85/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9600\n",
      "Epoch 86/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9600\n",
      "Epoch 87/150\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9467\n",
      "Epoch 88/150\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
      "Epoch 89/150\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9600\n",
      "Epoch 90/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9600\n",
      "Epoch 91/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9600\n",
      "Epoch 92/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9600\n",
      "Epoch 93/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9467\n",
      "Epoch 94/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9600\n",
      "Epoch 95/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9600\n",
      "Epoch 96/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9467\n",
      "Epoch 97/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9600\n",
      "Epoch 98/150\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9467\n",
      "Epoch 99/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9600\n",
      "Epoch 100/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9600\n",
      "Epoch 101/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9600\n",
      "Epoch 102/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9467\n",
      "Epoch 103/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9600\n",
      "Epoch 104/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9467\n",
      "Epoch 105/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9467\n",
      "Epoch 106/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9467\n",
      "Epoch 107/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9600\n",
      "Epoch 108/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9600\n",
      "Epoch 109/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
      "Epoch 110/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9600\n",
      "Epoch 111/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
      "Epoch 112/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9467\n",
      "Epoch 113/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9600\n",
      "Epoch 114/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9600\n",
      "Epoch 115/150\n",
      "75/75 [==============================] - 0s 227us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9467\n",
      "Epoch 116/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9467\n",
      "Epoch 117/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9467\n",
      "Epoch 118/150\n",
      "75/75 [==============================] - 0s 353us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9467\n",
      "Epoch 119/150\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9467\n",
      "Epoch 120/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9467\n",
      "Epoch 121/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9467\n",
      "Epoch 122/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9467\n",
      "Epoch 123/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9600\n",
      "Epoch 124/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9467\n",
      "Epoch 125/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9467\n",
      "Epoch 126/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9600\n",
      "Epoch 127/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9467\n",
      "Epoch 128/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9467\n",
      "Epoch 129/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9467\n",
      "Epoch 130/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9467\n",
      "Epoch 131/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9600\n",
      "Epoch 132/150\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9467\n",
      "Epoch 133/150\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9467\n",
      "Epoch 134/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9467\n",
      "Epoch 135/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9467\n",
      "Epoch 136/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9467\n",
      "Epoch 137/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9467\n",
      "Epoch 138/150\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9467\n",
      "Epoch 139/150\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9467\n",
      "Epoch 140/150\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9467\n",
      "Epoch 141/150\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9467\n",
      "Epoch 142/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9600\n",
      "Epoch 143/150\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9600\n",
      "Epoch 144/150\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9600\n",
      "Epoch 145/150\n",
      "75/75 [==============================] - 0s 273us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9600\n",
      "Epoch 146/150\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9600\n",
      "Epoch 147/150\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9467\n",
      "Epoch 148/150\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9467\n",
      "Epoch 149/150\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9467\n",
      "Epoch 150/150\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxcdbn48c8zk7Vp0nTf0jallKUt3WhZKzuyKFRla0GBCvbiTwQVFBAuIFe94tWrslwVtdgCUllECwIFKoiA0JZuQEuhhS5p031L0iSTmXl+f3zPJJPJTDJNO50053m/XvOaOes85yRznvP9fs/5HlFVjDHG+Fcg2wEYY4zJLksExhjjc5YIjDHG5ywRGGOMz1kiMMYYn7NEYIwxPmeJwPiCiJSLiIpIThrzXi0ibxyMuIzpCCwRmA5HRNaISEhEeiWMX+IdzMuzE5kxnZMlAtNRfQpMjQ2IyDFAYfbC6RjSKdEYs68sEZiO6hHgyrjhq4BZ8TOISDcRmSUiW0VkrYjcISIBb1pQRH4mIttE5BPgc0mW/YOIVIrIBhH5oYgE0wlMRJ4UkU0isltEXheRkXHTCkXk5148u0XkDREp9KZNEpG3RGSXiKwXkau98a+JyLVx62hWNeWVgr4hIh8DH3vjfuWtY4+IvCsin4mbPygi3xeR1SJS5U0fJCIPisjPE7blWRH5VjrbbTovSwSmo3obKBGRo70D9GXAownz3A90Aw4DTsUljmnetK8BnwfGAROAixOWnQmEgcO9eT4LXEt6XgCGA32ARcBjcdN+BhwLnAT0AL4HREVksLfc/UBvYCywJM3vA/gCcDwwwhte4K2jB/An4EkRKfCmfQdXmjofKAG+Cuz1tnlqXLLsBZwJPL4PcZjOSFXtZa8O9QLWAGcBdwD/DZwLvAzkAAqUA0GgHhgRt9x/AK95n/8BXBc37bPesjlAX2/ZwrjpU4FXvc9XA2+kGWupt95uuBOrWmBMkvluA55JsY7XgGvjhpt9v7f+M9qIY2fse4GVwOQU860AzvY+Xw88n+2/t72y/7L6RtORPQK8DgwloVoI6AXkAWvjxq0FBnqfBwDrE6bFDAFygUoRiY0LJMyflFc6+RFwCe7MPhoXTz5QAKxOsuigFOPT1Sw2EbkJV4IZgEsUJV4MbX3XTODLuMT6ZeBX+xGT6SSsash0WKq6FtdofD7wl4TJ24AG3EE9ZjCwwftciTsgxk+LWY8rEfRS1VLvVaKqI2nb5cBkXImlG650AiBeTHXAsCTLrU8xHqAG6BI33C/JPI3dBHvtAbcAlwLdVbUU2O3F0NZ3PQpMFpExwNHAX1PMZ3zEEoHp6K7BVYvUxI9U1QjwBPAjESkWkSG4uvFYO8ITwA0iUiYi3YFb45atBF4Cfi4iJSISEJFhInJqGvEU45LIdtzB+8dx640CM4D/FZEBXqPtiSKSj2tHOEtELhWRHBHpKSJjvUWXAF8SkS4icri3zW3FEAa2AjkicieuRBDze+C/RGS4OKNFpKcXYwWufeER4GlVrU1jm00nZ4nAdGiqulpVF6aY/E3c2fQnwBu4RtMZ3rTfAXOBpbgG3cQSxZW4qqXluPr1p4D+aYQ0C1fNtMFb9u2E6TcD7+EOtjuAe4GAqq7DlWxu8sYvAcZ4y/wCCAGbcVU3j9G6ubiG54+8WOpoXnX0v7hE+BKwB/gDzS+9nQkcg0sGxiCq9mAaY/xERE7BlZzKvVKM8TkrERjjIyKSC9wI/N6SgImxRGCMT4jI0cAuXBXYL7McjulArGrIGGN8zkoExhjjc4fcDWW9evXS8vLybIdhjDGHlHfffXebqvZONu2QSwTl5eUsXJjqakJjjDHJiMjaVNOsasgYY3zOEoExxvicJQJjjPG5Q66NIJmGhgYqKiqoq6vLdigHTUFBAWVlZeTm5mY7FGPMIa5TJIKKigqKi4spLy8nrlvhTktV2b59OxUVFQwdOjTb4RhjDnEZqxoSkRkiskVE3k8xXUTkPhFZJSLLRGR8e7+rrq6Onj17+iIJAIgIPXv29FUJyBiTOZlsI/gj7slSqZyHe9zfcGA68Ov9+TK/JIEYv22vMSZzMlY1pKqvi0h5K7NMBmap6+PibREpFZH+Xl/xvlbfEKEuHKVbYcev/39/w2527g3xmeFJ71NpYUdNiFeWb+aSCWXNktneUJiH31xDfUMk5bI5wQBXHD+Ynl3zAXhiwXoqdu5FRPjS+IEM6VnUbP55KzazdP0uAE4/qg/jBncHYOGaHbz+0dZ92s6B3Qu5bOLgxm149O21hCNNfbYV5efw1UlDyQ0GCIWjPPzmp9TUh/fpO4xpy5lH92XMoNIDvt5sthEMpHkf6hXeuBaJQESm40oNDB48OHFy1m3fvp0zzzwTgE2bNhEMBund2x0Y58+fT15eXpvrmDZtGrfeeitHHnkkG3fXUV3XwJH9SsjL6bgXdqkqNz2xlIqde5l/+1kU5bf973TfvI/541trGNSjCycO69k4/vH56/mfuStpraCjClV1Ddz+uREs37iH7z29rHHayk1V/OYrxzYO76lr4Po/LabWSyzPLatk3k2nElW4cfYSNuyqbfW7Er8XYOSAbowa2I3f/nM1v339k8blY9P7lOTzxXFlzFm6kf9+4UOAtL/DmHT0KSnodIkg2U8kaQ94qvoQ8BDAhAkTOlwveT179mTJkiUA3H333XTt2pWbb7652Tyxh0QHAskP7A8//DAAoXCEqroGAHbuDdG3pCCDke+fJet3sXJzFQDPLdvYeMacSl1DhGcWuydJzl6wrjERqCqz569jzKBS/vaNk1Mu//VH3+XpRRv47jlH8ecF68jLCTD/+2fy4KurePjNNWytqqd3sSstzFmykdqGCH/9xsl8vLmK7z61jAVrdlLXEGHDrlrunzqOC8YMSGs7d+9t4Lgfv8ITC9dzRN9innq3gnNG9uW3X5kAQDSqnP7z15g9fz1fHFfGnxes47BeRcy76VSrwjOHhGyeblbQ/JmyZcDGLMWSEatWrWLUqFFcd911jB8/nsrKSqZPn86ECRMYOXIk99xzT+O8kyZNYsmSJWzZU8ukkUN44N57OPXEiZx44ols2bIli1uR2uz56ynMDVLeswuzF7T53HfmfrCJ3bUNjOhfwgvvb2LX3hAAi9bt4uMt1UydOKjV5accN5gdNSGeXbqRZxZv4LxR/SjtksdlEwcTjipPL6ponPfPC9ZzVL9ixpR143Oj+1Ocn8Ps+euYvWAd3bvk8tmRfdPezm5dcjn/mP48s3gDzy3byPaaEFOOa0p6gYBw2cRBvPPpDl5evpkFa3Zy2cRBlgTMISObJYI5wPUiMhs4Hth9INoHfvDsByzfuGe/g4s3YkAJd12QznPNW1q+fDkPP/wwv/nNbwD4yU9+Qo8ePQiHw5x++ulcfPHFjBgxAnBnxjtrQlTt2cPZZ5zG9bfcyUM/vZsZM2Zw6623tvItB191fZhnl23kgjH9OaJvMT/8+wpWbqriyH7FKZd5fP46BvUo5KcXj+bz97/BM4s3MO3kocyev46ivGCbZ+iTDu/FwNJC7p7zAVX1YS7zEsfhfboysbw7f16wnv845TA+2LiH9zbs5u4LRiAidMnL4cKxA3jq3Qqiqlx5Yjn5OcF92t7LJg7imcUbuOtvHzCgWwGnJLSJXDy+jJ+/9BHf+fMScgLCl8aX7dP6jcmmjCUCEXkcOA3oJSIVwF1ALoCq/gZ4HvcM11XAXmBapmI5WGobItQ3RMhpiDQ2JA4bNozR48azp9ZV9zw881FmzXyYSCRMZWUlC5cso2zocCJRZefeEKWRKIWFhVz0hQv4sHIPw44+hvfefadx+cTve3n55oO6jTEL1+xgbyjClOMGU96ziHtf/JD7//Exk8cOTDp/VV0Db3+yg++ecySjBnZjdFk3HntnHf27FfLcskomjx3QZhtDMCBcOmEQv3jlI8p7duHEw5raGKZMHMxNTy5lxptreHftDvJyAnxxXNPBeOpxg3nsnXXevK2XPJI5fmgPhvYq4tNtNXx10lCCgeZn+31KCjjzqD68tHwz543q11hFZcyhIJNXDU1tY7oC3zjQ39veM/f9FY5GWb2lml21DYQkxIZdtQAUFRXx6dYaQpEoaz9dzX3338djz86jpFs3brthOhXbdrNmew114QjbqkP0DgbIy8sjIEL3ojxCUdhVU8ea7TUtvnN7dYivzcleT6xH9y9h3KBSRITzj+nP35Zs5LllqQt1eTkBLj7WHZyvOH4wtzz9Htc9+i4Alx+f3kUAl0wo48HXVnHF8UOaVb2cf0x/fvj35fzXc8sBuGh8Gd26NF11NWpgN8YOKqUgN8DwvqlLLamICF8+YQj3vvghl0xIfrb/5ROG8NLyzXz5hCH7vH5jsqlT3FncEeza20BUlW6FueTkBdlTGyYnEiUaVUKRKANKC6nKDdOjtIRxw/qzefNm5v/rVS668HMM79OVwtwgg3sUcnifro3r7FtSQP9uBZQU5jA8bnyM7sznuW9OOpib2cyg7l0aD8b3XjSar33msFbn716U19j4fcmxgxgzqJRwRCnKz2For6JWl40ZUFrIG7ecTq+i5mfchXlB5n77FLbsqQdoth9jHrnmOAL7UW8/7aRyLhjTnz7FyRvwTzmiN+98/8wO3cBvTDKWCA4AVWVHTYjC3CAFuUHy83NQlD21DYSjSk4gQI+iPE46/jhGjRzJxPFjOeywwzj55JPJywlSmJdDQISC3Bxyg03t9wER8nKC5AQCFOa1/FPl5QQ4emC3g7mpKRXkBhm1D7EEAsJR/Ura9V2pDsR9igtSTgMoLti/+zICAWl1/YAlAXNIOuSeWTxhwgRNfDDNihUrOProo7MUkbsZatWWagaWFjbe7LR6SzWhSJRwROlVnEf/boUH/Huzvd3GmEOHiLyrqhOSTeu4dyt1INGEZBmJKg2RaONre3WIgAilcXXS3YvyaIhEUZTuXdq+ocwYY7LFqobaEApH+WhzFYN7dKGkMJeGSJSVm6paJIfuXfIIxt0sVlqYS+VuocCrLjLGmI7KEkEb9obCRFXZVl1PSWEuO/eGiKrSv1shsSsIRaAkof45EBAO61XU4jJDY4zpaCwRtCHWV011fZj6cISdNSGK8nPSuk48WQOvMcZ0NNZG0IbaUIS8YAABKnbWUh+O0sPq/I0xnYidsrZCValtiNCtMJdwRNlT10AwIIdE99DGGJMuSwStaIhEiUSVwtwgOQUB9tQ1UNolj0BCvf+B6IYaYMaMGZx//vn069fvwG5IR7DqFZhzA0TD0LUvfHUu5HWBTe/D7KkQrk+9bDAfLpsFA8a1nBYJw58uhWOvghGT3bgnroJ1/3afT/g6TPq2+/z892D5X/dvO7r2hWkvQH7cDWvpbMP+mHgtnPo993nu7fDek63P3+8YuOIp13j1wV/hxVtBo1Dc38We1wUqFsIL34PLn4SinrB1JTx2CYTjnnoXzIcpj0L/MVC3Gx69GM66C8qT3MSoCo9dDJveaz22Yy6Bc37kPv/zp7Dg9+7z4BPh0pnp7Y9Utq+Gp74KF8+AnsOaxtfudLGf8yMYfELq5VXhyatg6Clunx9IH7/s/v819fM2yO0CX/kL9Gj9xsxMsETQitqQ+6MV5gUpzA3Sr6SA7kUtD+rpdEOdjhkzZjB+/PjOmQhWPAe1u9yP7KMXoHIpDDkRPn4Jdq2D8VeCJKmpVIVFs+Cjl5InglWvwOp5kF/sEkF9FSz/G5RNhIa98MYv4fivQ90ud9Apmwh9jmrfNoRq3EH4g7+4eGPe+TXUbIPRl7Zvva3ZsAjevA9O/AY01MI7v4UBY6Fviq5U9lTCx3Nh7VtQfjK88b8QyIFBx8P7T7lEOPZyePNXsOFdWPIYnHyDW2/1ZhgzpWld7z0Fb/8GvvhrWPYEVMx3+zNZIlj7pvtbHHEuFKf4/938Acx/CCZ9B3Ly3Xb1GApderq4Nr0P/Ua1f1/N/x1ULnHfcd69TeOXzoYNC902t5YIKha6/53182H81RA8gIfHN37pksCR5yWfrur+Fgv+0JQoDyJLBK2obYggCAU5QUSEPu24a3TmzJk8+OCDhEIhTjrpJB544AGi0SjTpk1jyZIlqCrTp0+nb9++LFmyhMsuu4zCwsJ9KkkcEiqXQtmxcMEv4edxiaByKZQOgQvvT73s2rfcfMksmtW0fnAHExROudkdbGZNhhXPwu517of4hf9rfra4L1Shcpn7zlgiqNsD7/8FRl0EF/yqfettzdp/w8PnujP72h0QbXD7qk+KGwlDNfDzo1yMeUVuv5z3P3Dc12DjYjf+8LNh5fNu/kWzYOI1LsGN+ELCNog7iJ73E1jkna2vegV2V0C3hP6WFs2C/BK4+GFX4khm83L49Ymw9HEoLIVQFZz/P9DriKaYz/9p+/ZTQx0sm+0+L50NZ/0AcguaTiQAPprrEmVJ/+TriG1jVaXbziNbe9LuPti2Cta+AWfeCZ+5KfV8tTvdvjnzLsg5uL/9zpcIXri17eJpmro1RChBCQwa534M++j999/nmWee4a233iInJ4fp06cze/Zshg0bxrZt23jvPRfnrl27KC0t5f777+eBBx5g7NixByT+DiPS4M4Gj5/uzha79m06cFcudVUPrek/Bta93XJ81Sb46EUo6AY7P3Uljth6+4+Boj4uybz7R9izAYZMan8SAFfVcuxVMPf77qDWdwS8/7QreYy/qv3rbc3gE9yBctFMd6AoOy51EgB38D/mYljyJ1cNl1MAoy9xsY+/El65C+bd7aadfKM7S37hFqjf07yUA2743YddddSm9+CkG+Ct+2Dxo3BaXLfotTvdmfTYK1InAXD7q2yi25aCUuh1pCupiMDRF7gD+dk/gNx23IX/4XMujpO/BW/+0iX/0Ze4s/wty5tiX/IonPLdlsvXV7mEPmYqrJrnYjxQiWDxLJCg2z+tGX8VrJgDK/8OI794YL47TXbVUAqKElXdr07KXnnlFRYsWMCECRMYO3Ys//znP1m9ejWHH344K1eu5MYbb2Tu3Ll069Yx+gvKmK0fQqQe+nsJrv8YV4Sv3eUO4Okkgj0Vrvol3pLH3Fn+6be74U3vufV27esSTiDgDmZr33Dfc+wBOFiPngLBvKazzEWzoM8IKEt65/7+ix3A178D2z5KbxvGX+Xq+t9/ylWXFbpnNTP2cldNtPhRGHQCnHqLO4tf/Aj0PByGnNR8PQPGufaGxY9ATqE7mz3sdLd8NK6ue9mT7vvSjW3bR66aafyVTc/yPPYq1w6x4tn09kuiRTOhdDCc8Z8u+cfO7hfNhNwi18ZS/hlY9AhEoy2Xf/9paKhxbQNjL28qPeyvSINLyq1VmcUMOx26DWr63zqIOl+JoB1n7vHCkSgbdtUS9Z6PO6C0kIKucfcMqMKeja5eMzehqmjPRti7A6Qetq9Gq7fy1alf5L9u+3bTPIWl0KUny5Yt44UXXuC+++7j6aef5qGHHtqvuA+4N++D3kfCEec0H79oFnz49+bjyifBSd9Mva7Gs/S4RLDqFVcXC67OuzWx6ZVL4XDXKE806mIZMglGfsk1fFYubVnCGHsFvPpj17h79AWtf086inrCUZ93B8ftH8PGRXDuTzL7cOIxU+GVH7iz+3TOFAeMhX6jYdOy5mf5Xfu4OuoVz7oDb6z0sHBG84NyjIg7cD9/M4z8gvvfHX8lPDXNVbnleT3Gbljk9nlbCR1c/C/e6hrW49sjhkyC7kPhlbvdQXlfqMKnr8Ppd7h6/fFfgX/80DV+f/ovOOYi14Y0/ir4y7XwyGTXMBuvcqlL6AOPdYnzzV+6ixBK0nucaUr1VVCzNb0kGQjCuC/Daz+Bxy5N/j818VoYfvb+xZRE50sE+2lHTYjdtQ0U5gYpysuhpCBhF0XqoWYLREKuoSumodY1tkXD7iw12sBZnzmei6+5kRuvvYJePbuzfetWampWUTh4LAVdunDJJZcwdOhQrrvuOgCKi4upqqo6iFubwq518PKd7uqF4Z9t+ocM1bhqgtwuUOw96nHvDndQH32ZO9AkU7kU8ro2XQ3Rf4y7imXpn9xwvzYOIP1Ge+tZ0pQI1vwLdq6B074PXXtDyUB3pdDWD+GozzUtW9LfVQV07d2+KodkTr7R7aOarTD01OYHtEwo6gWn3QJ5xU0H37accQcsnwNDEp4BHaujHvEF937i9e7Md9xXkq9n9GWw+lW3zeD27RHnQdVGV50E0G2gK12kI7+rO2sPVbntigkEXMxv3e/q6PfVkElNB9vxV8Pq19zvsd8ot43gTgSGnwPVm1zpI17Xvq5dScRVH57w/1wDeHtiSXT0BXD4WenNe+w0l9SqNyWfHmr5XJIDwRJBHFVlx94QXfNzOKx3y/7sAQi75+xSt9tduhi7smDvdkCgSy/oWgK9j+KYU4/irnuqOWvK14lGo+TmBPnND28iGFrONdd/B1VFRLj3XneFw7Rp07j22muz31i8+FFAYcdq92OIXSXywV/dj//yJ1xDL8DWj+DBia74O+lbyde3cYk7mMf6YoqVDFY85w7gXXsnXy6msBS6lzdvMF4007UNjLiwaZ0fzXUJpn9CCeP029Ld8vQMGAtfm3dg19mWZPXarTninJalOXDVPZc92jTccxhcPjv1egpKYOqfmoZz8lufPx0nXJd8/DEXu9f+6tobpv295fjcArjiifTWce5/738c7VHcF6Y9f9C/1hJBnJr6MKFwlH6tXR0U8RIB6q7i6NrHVVPs3QEFpdwd90B6gMsvv5zLL7/cW0Rdw1Uwj8WLF7dY9aWXXsqll2bgEsR9EY24RDBkkqtzXzSrKREsmuUaLuMvwet9hLsGfNEsd9aYWJyNRtx6JsQ9ibRbGRT2cPsv8aCdSv+xrkQAbl+veNadPcXO8vuPcY1ssc/GmLRZY3GcHTUhggFp0YFcM5F6QFz1yN7t7uBet8tVBxX1TL0cuINkl54Qqm5+405Hsmqeu8Lm+Onuuvjlf3NXY2z5ENa/nbwuefxVTaWHRNs+hnBt84OzSNNwugft/mNcVVDtTnd5YCTUvP47tp7CHi0vbTTGtMpKBJ5wJMruujA9i1reOdx8xpC7aqRLL3dt+p4NrkEomOfqwdvSpYerd9xdkX59byp1u13D0oH00YtQ1NvVA3cfCgt+B89+y31XINc1XCYaMdldgjjvHhh2RvNpW1e698QDfv8x8Mmr+5YIAF6+Cz55zTXqxd98FJ9YMtlwa0wn1GkSQay+vb2q68OoarOHyyQVqXc3exSWugN6zVY3vltZegegYF5TtUh9+xuGNVYSeS0DdZln3OG2sf9oOOy0pm4Zxl/VvIEvJq8LHHct/Ovn7jLHRN2HQs/hzccdcY67bnvQcenFNPBYl3wXzXR3IJ95Z/Ppxf3cJZFHnp/e+owxjTrFoyo//fRTiouL6dmzZ7uTQeWuWrbVhBg5oKT1ewcql7nLy0oHuWqhmH393v3Y76rK9u3bqaquZmh5ebvXk1L8tuzLNra2TQfiLH1/9rcxPtfaoyo7RYmgrKyMiooKtm7d2u51bK2qR4GVe1p5zoBGYXclFNZCfnW7v+tAKCgooKwszVLI/tiX9XekWIwxaesUiSA3N5ehQ4e2PWMK0ahy6Q9e4sKxA/jRF1u5fb9yGTxxKVwyE44+vt3fZ4wxHYlvrxoKR9yziAHW79xLVX2YUQPb6Oph5xr33r08o7EZY8zB5NtE8OIHm/jsL17nvYrdvL/B3SF5TFuJYNda9959SIajM8aYg6dTVA21x5Y97iEijy9YR0lBLrlBYXjfNi7/3LnG3c0a68TLGGM6Ad8mgqq6MABzlmzkyH7FHNG3mPycYOsL7VzrejY0xphOxLdVQ9X1Dd57mHfX7my7WghcicDaB4wxnYyPE0GY3sX5DOvt7u4d2VYiiEZdj5PWPmCM6WQymghE5FwRWSkiq0Tk1iTTh4jIPBFZJiKvichB6yRmT12Y4oIcpkwcDMDothJBzRZ3V7FVDRljOpmMtRGISBB4EDgbqAAWiMgcVV0eN9vPgFmqOlNEzgD+G0jRMfqBVV0Xpjg/h6tOKmdYnyJGl7WRCPZud+/JulgwxphDWCZLBMcBq1T1E1UNAbOByQnzjABiHbu/mmR6xlTXhykuyCUvJ8AZR/Vtu2uK2l3uvaA088EZY8xBlMlEMBBYHzdc4Y2LtxS4yPv8RaBYRFr05Swi00VkoYgs3J9uJOJV1TXQNX8fCkR1XiIotERgjOlcMpkIkp1iJ/ZKdjNwqogsBk4FNgDhFgupPqSqE1R1Qu/ebTzNKk3VdWG6Jj6GsjWxR9sVdPIHzRtjfCeTiaACGBQ3XAZsjJ9BVTeq6pdUdRxwuzcu4WGimVFV7xqLU6rZDn/4LOz41A1b1ZAxppPKZCJYAAwXkaEikgdMAebEzyAivUQkFsNtwIwMxtMoGlXXRtBa1dCGha5v/Qqvy+tY1ZCVCIwxnUzGEoGqhoHrgbnACuAJVf1ARO4REe+J45wGrBSRj4C+wI8yFU+8vQ0RVGm9aijWwVzsaqHaXZDfDQJt3H1sjDGHmIx2MaGqzwPPJ4y7M+7zU8BTmYwhmao6d1dxcWvPJt7pdTAXSwR1u600YIzplHx5Z3G1189Qq1cNJZYI6nZBoSUCY0zn48tEUFXvJYJ9rRqyhmJjTCfkz0TglQhKUiUC1aZnDzQrEVgiMMZ0Pr5MBE1VQynaCPZuh5D3TOK9O9y7tREYYzopfyYCrwvqlFVDsYbiot5WNWSM6fR8mQhiVUMpbyjb6d1ENmC8SwQNdRCutaohY0yn5OtEUJSXIhHE2gcGHgvRBthd4YatRGCM6YR8mQiq68MU5QUJBlL0OLpzjasWKnXPKmDHavduzyo2xnRCvkwEVXUNbd9MVjoEungdoW73EoE1FhtjOiFfJoLq+jZ6Ho09mziWCGIlAqsaMsZ0Qr5MBFV1rfQ8Ggm7NoHuQ6BLDzcuViKwxmJjTCeU0b6GOqpmiSAagbVvQrjeDe/dDhpJKBF84t6tRGCM6YR8mQiq68MMKC1wAx+9CLMvbzlT76MhvxgCubDbe9CatcFlr30AABStSURBVBEYYzohXyaCqroGimN3FcduHvvKX92BHyC3C/Q5GkRcqaB6kxuXk5edgI0xJoN8mQiaPaayehME8+Cw09yBP1EsEVi1kDGmk/JdY3EkqtSEIk1dUFdthq79kicBaGowtoZiY0wn5btEUF2f0L1E9SYo7pt6gViDsbUPGGM6KUsEVZuhazqJwEoExpjOyX+JILEL6qpKKO6XeoGiXu7dqoaMMZ2U7xJB0/OKc1yvonW7XBtBKlYiMMZ0cv5LBPGPqaze7Eam00ZgJQJjTCflu0QQqxoqzo9LBK2WCLyrhqyx2BjTSfkuEcSeRdC1IAeqNrmRaV01ZCUCY0zn5LtEEApHACjICcZVDfVPvUDfUXD6HXDkuQchOmOMOfh8d2dxOKoABIPiSgQShC69Ui8QCMKp3z1I0RljzMHnuxJBxEsEOQFxN5N17QMB3+0GY4xp5LsjYGOJIOCVCFq7mcwYY3zAd4mga816bsl5nByNuLuKW7uZzBhjfMB3iWDw9n/x9ZxnCaya61UNWYnAGONvvksEgYh7EpksfBhqtlmJwBjjexlNBCJyroisFJFVInJrkumDReRVEVksIstE5PxMxgMgXiJg9TxALREYY3wvY4lARILAg8B5wAhgqoiMSJjtDuAJVR0HTAH+L1PxxAQioeYjWrur2BhjfCCTJYLjgFWq+omqhoDZwOSEeRQo8T53AzZmMB4AAtF69pLvnkgGrd9VbIwxPpDJRDAQWB83XOGNi3c38GURqQCeB76ZbEUiMl1EForIwq1bt+5XUMFoiHry4MTr3R3FPYbt1/qMMeZQ12YiEJHrRaR7O9ad7NmPmjA8FfijqpYB5wOPiEiLmFT1IVWdoKoTevfu3Y5QmgQi9YTIheFnw00fWq+ixhjfS6dE0A9YICJPeI2/KR7u20IFMChuuIyWVT/XAE8AqOq/gQKglf4e9l8wGqKB3Ex+hTHGHFLaTASqegcwHPgDcDXwsYj8WETaqlNZAAwXkaEikodrDJ6TMM864EwAETkalwj2r+6nDcFoiAbJy+RXGGPMISWtNgJVVWCT9woD3YGnROSnrSwTBq4H5gIrcFcHfSAi94jIhd5sNwFfE5GlwOPA1d53ZUxOtJ6QWInAGGNi2ux9VERuAK4CtgG/B76rqg1eXf7HwPdSLauqz+MagePH3Rn3eTlwcvtCb5+ghmjASgTGGBOTTjfUvYAvqera+JGqGhWRz2cmrMwJRhuos6ohY4xplE7V0PPAjtiAiBSLyPEAqroiU4FlSk60ngarGjLGmEbpJIJfA9VxwzXeuENSjoYIB6xEYIwxMekkAolvwFXVKIfwk81ytMGuGjLGmDjpJIJPROQGEcn1XjcCn2Q6sEzJ1RARKxEYY0yjdBLBdcBJwAbcTWLHA9MzGVQm5WqIsJUIjDGmUZtVPKq6BXczWKeQa20ExhjTTDr3ERTguoIYibvzFwBV/WoG48qYXG0gEsjPdhjGGNNhpFM19Aiuv6FzgH/i+gyqymRQGRONkkuYiF0+aowxjdJJBIer6n8CNao6E/gccExmw8oQ7+lkkaCVCIwxJiadRNDgve8SkVG4B8iUZyyiTArXAdhVQ8YYEyed+wEe8p5HcAeu99CuwH9mNKpMCbvHVEatRGCMMY1aTQRex3J7VHUn8Dpw2EGJKlO8EkHUSgTGGNOo1aoh7y7i6w9SLJkXdm0EViIwxpgm6bQRvCwiN4vIIBHpEXtlPLJMiJUILBEYY0yjdNoIYvcLfCNunHIoVhNFXBuBBq1qyBhjYtK5s3jowQjkoPBKBGolAmOMaZTOncVXJhuvqrMOfDgZZlVDxhjTQjpVQxPjPhfgHja/CDgEE4FrLLYSgTHGNEmnauib8cMi0g3X7cShxxKBMca0kM5VQ4n2AsMPdCAHhZcIyLFEYIwxMem0ETyLu0oIXOIYATyRyaAyJdpQRwDQYEGb8xpjjF+k00bws7jPYWCtqlZkKJ6MiobrXREo10oExhgTk04iWAdUqmodgIgUiki5qq7JaGQZoA217oO1ERhjTKN02gieBKJxwxFv3CEn2uAuHxVrIzDGmEbpJIIcVQ3FBrzPh+StudpQR1gDBHLswTTGGBOTTiLYKiIXxgZEZDKwLXMhZU40XE89ueQEJNuhGGNMh5FOG8F1wGMi8oA3XAEkvdu4w2uoJ0QuwUB7rpo1xpjOKZ0bylYDJ4hIV0BU9dB8XjGg4TorERhjTII2T41F5MciUqqq1apaJSLdReSHByO4Ay5cR73mErREYIwxjdKpIzlPVXfFBrynlZ2fzspF5FwRWSkiq0Tk1iTTfyEiS7zXRyKyK9l6DhSNtREELREYY0xMOm0EQRHJV9V6cPcRAG1efykiQeBB4Gxcu8ICEZmjqstj86jqt+Pm/yYwbh/j3zfhWBuBJQJjjIlJJxE8CswTkYe94WnAzDSWOw5YpaqfAIjIbGAysDzF/FOBu9JYb/vZVUPGGNNCOo3FPxWRZcBZgAAvAkPSWPdAYH3ccAVwfLIZRWQIMBT4R4rp04HpAIMHD07jq5OTxjYCu2rIGGNi0j0ibsLdXXwR7nkEK9JYJtlptyYZBzAFeEpVI8kmqupDqjpBVSf07t07nXiTi4SsRGCMMQlSlghE5AjcAXoqsB34M+7y0dPTXHcFMChuuAzYmGLeKTR/JnJGSKSOEMUUWiIwxphGrZUIPsSd/V+gqpNU9X5cP0PpWgAMF5GhIpKHO9jPSZxJRI4EugP/3od1t4tYG4ExxrTQWiK4CFcl9KqI/E5EziR5dU9SqhoGrgfm4qqSnlDVD0TknvguK3Aljtmqmqra6IAJROrtPgJjjEmQsmpIVZ8BnhGRIuALwLeBviLya+AZVX2prZWr6vPA8wnj7kwYvrsdcbeLREN2H4ExxiRos7FYVWtU9TFV/Tyunn8J0OLmsENBIGJ9DRljTKJ9OiKq6g5V/a2qnpGpgDIpELE2AmOMSeSfU2NVAtEG6u3OYmOMacY/iSBcD0BIrURgjDHxfJQI3GMqrURgjDHN+SgRuBKBayPwz2YbY0xb/HNEjDQlgqBdPmqMMY38kwhiJQJrIzDGmGZ8lAisjcAYY5LxUSKIbyOwRGCMMTE+TAR5ViIwxpg4PkoErmoopDl21ZAxxsTxzxExrmrISgTGGNPER4kg1licZ20ExhgTxz+JIBICIEQuAUsExhjTyD+JwCsRRAO5WQ7EGGM6Fh8lAtdG0BDIy3IgxhjTsfguEUQCBVkOxBhjOhb/JILyScwdcD1RKxEYY0wzKZ9Z3OkMHM/rvXORLZuyHYkxxnQo/ikRAJGo2j0ExhiTwFeJIBxVu6vYGGMS+OqoaCUCY4xpyVeJwJUILBEYY0w8XyWCSDRqJQJjjEngq0QQjljVkDHGJPJVIohElRx7XrExxjTjq0QQjipBu2rIGGOa8dVRMWKNxcYY04KvEkHYGouNMaaFjCYCETlXRFaKyCoRuTXFPJeKyHIR+UBE/pTJeKxEYIwxLWWsryERCQIPAmcDFcACEZmjqsvj5hkO3AacrKo7RaRPpuIB10ZQkGuJwBhj4mWyRHAcsEpVP1HVEDAbmJwwz9eAB1V1J4CqbslgPFYiMMaYJDKZCAYC6+OGK7xx8Y4AjhCRN0XkbRE5N9mKRGS6iCwUkYVbt25td0DuPgJfNYsYY0ybMnlUTHbqrQnDOcBw4DRgKvB7ESltsZDqQ6o6QVUn9O7du90BWYnAGGNaymQiqAAGxQ2XARuTzPM3VW1Q1U+BlbjEkBHhaJSg3VBmjDHNZDIRLACGi8hQEckDpgBzEub5K3A6gIj0wlUVfZKpgKxEYIwxLWUsEahqGLgemAusAJ5Q1Q9E5B4RudCbbS6wXUSWA68C31XV7ZmKKWzdUBtjTAsZfVSlqj4PPJ8w7s64zwp8x3tlnJUIjDGmJV9dQmN9DRljTEu+OipaicAYY1ryVSIIR6yvIWOMSeSrRGAlAmOMaclXiSAcVbuPwBhjEvgqEViJwBhjWvJNIlBVu2rIGGOS8M1RMer1cmQlAmOMac43iSAcjQLYVUPGGJPAN4kg4hUJrERgjDHN+SYRhL1EYCUCY4xpzjeJIBKxEoExxiTjm0TQWCII+maTjTEmLb45KlobgTHGJOebRGBXDRljTHK+SQRWIjDGmOR8kwjsqiFjjEnON4mgqUTgm002xpi0+Oao2BCxNgJjjEnGN4nA2giMMSY53ySCpvsILBEYY0w83yQCKxEYY0xyvkkE4YhdNWSMMcn4JhHYVUPGGJOcb46KsTuLc6yNwBhjmvFNIrA2AmOMSc43icDuLDbGmOR8kwisjcAYY5LzzVHRSgTGGJOcbxJBJNZYbInAGGOayWgiEJFzRWSliKwSkVuTTL9aRLaKyBLvdW2mYrH7CIwxJrmcTK1YRILAg8DZQAWwQETmqOryhFn/rKrXZyqOmMY2Art81BhjmslkieA4YJWqfqKqIWA2MDmD39cqayMwxpjkMpkIBgLr44YrvHGJLhKRZSLylIgMSrYiEZkuIgtFZOHWrVvbFYxdNWSMMcll8qiY7NRbE4afBcpVdTTwCjAz2YpU9SFVnaCqE3r37t2uYKxEYIwxyWUyEVQA8Wf4ZcDG+BlUdbuq1nuDvwOOzVQwdtWQMcYkl8lEsAAYLiJDRSQPmALMiZ9BRPrHDV4IrMhUMOU9izj/mH7WWGyMMQkydtWQqoZF5HpgLhAEZqjqByJyD7BQVecAN4jIhUAY2AFcnal4PjuyH58d2S9TqzfGmEOWqCZW23dsEyZM0IULF2Y7DGOMOaSIyLuqOiHZNLuExhhjfM4SgTHG+JwlAmOM8TlLBMYY43OWCIwxxucsERhjjM9ZIjDGGJ875O4jEJGtwNp2Lt4L2HYAw8kEi/HAsBgPjI4eY0ePDzpOjENUNWlnbYdcItgfIrIw1Q0VHYXFeGBYjAdGR4+xo8cHh0aMVjVkjDE+Z4nAGGN8zm+J4KFsB5AGi/HAsBgPjI4eY0ePDw6BGH3VRmCMMaYlv5UIjDHGJLBEYIwxPuebRCAi54rIShFZJSK3ZjseABEZJCKvisgKEflARG70xvcQkZdF5GPvvXuW4wyKyGIRec4bHioi73jx/dl7Al024ysVkadE5ENvX57YAffht72/8fsi8riIFGR7P4rIDBHZIiLvx41Lut/Euc/7/SwTkfFZjPF/vL/1MhF5RkRK46bd5sW4UkTOyVaMcdNuFhEVkV7ecFb2Y1t8kQhEJAg8CJwHjACmisiI7EYFuCez3aSqRwMnAN/w4roVmKeqw4F53nA23Ujzx4jeC/zCi28ncE1WomryK+BFVT0KGIOLtcPsQxEZCNwATFDVUbgn9k0h+/vxj8C5CeNS7bfzgOHeazrw6yzG+DIwSlVHAx8BtwF4v50pwEhvmf/zfvvZiBERGQScDayLG52t/dgqXyQC4Dhglap+oqohYDYwOcsxoaqVqrrI+1yFO4ANxMU205ttJvCF7EQIIlIGfA74vTcswBnAU94s2Y6vBDgF+AOAqoZUdRcdaB96coBCEckBugCVZHk/qurruEfExku13yYDs9R5GyhNeOb4QYtRVV9S1bA3+DZQFhfjbFWtV9VPgVW43/5Bj9HzC+B7QPwVOVnZj23xSyIYCKyPG67wxnUYIlIOjAPeAfqqaiW4ZAH0yV5k/BL3zxz1hnsCu+J+iNnel4cBW4GHveqr34tIER1oH6rqBuBnuDPDSmA38C4daz/GpNpvHfU39FXgBe9zh4nRexb7BlVdmjCpw8QYzy+JQJKM6zDXzYpIV+Bp4Fuquifb8cSIyOeBLar6bvzoJLNmc1/mAOOBX6vqOKCG7FelNePVs08GhgIDgCJcFUGiDvM/mURH+7sjIrfjqlcfi41KMttBj1FEugC3A3cmm5xkXNb/7n5JBBXAoLjhMmBjlmJpRkRycUngMVX9izd6c6y46L1vyVJ4JwMXisgaXHXaGbgSQqlXxQHZ35cVQIWqvuMNP4VLDB1lHwKcBXyqqltVtQH4C3ASHWs/xqTabx3qNyQiVwGfB67QppuhOkqMw3BJf6n32ykDFolIPzpOjM34JREsAIZ7V2nk4RqU5mQ5plh9+x+AFar6v3GT5gBXeZ+vAv52sGMDUNXbVLVMVctx++wfqnoF8CpwcbbjA1DVTcB6ETnSG3UmsJwOsg8964ATRKSL9zePxdhh9mOcVPttDnCld9XLCcDuWBXSwSYi5wK3ABeq6t64SXOAKSKSLyJDcQ2y8w92fKr6nqr2UdVy77dTAYz3/lc7zH5sRlV98QLOx11hsBq4PdvxeDFNwhULlwFLvNf5uHr4ecDH3nuPDhDracBz3ufDcD+wVcCTQH6WYxsLLPT241+B7h1tHwI/AD4E3gceAfKzvR+Bx3FtFg24g9U1qfYbrkrjQe/38x7uCqhsxbgKV88e+838Jm7+270YVwLnZSvGhOlrgF7Z3I9tvayLCWOM8Tm/VA0ZY4xJwRKBMcb4nCUCY4zxOUsExhjjc5YIjDHG5ywRGJNARCIisiTudcDuVBaR8mS9VBqTTTltz2KM79Sq6thsB2HMwWIlAmPSJCJrROReEZnvvQ73xg8RkXle//LzRGSwN76v11/+Uu91kreqoIj8TtzzCV4SkcKsbZQxWCIwJpnChKqhy+Km7VHV44AHcP0u4X2epa5//MeA+7zx9wH/VNUxuP6PPvDGDwceVNWRwC7gogxvjzGtsjuLjUkgItWq2jXJ+DXAGar6iddZ4CZV7Ski24D+qtrgja9U1V4ishUoU9X6uHWUAy+re/ALInILkKuqP8z8lhmTnJUIjNk3muJzqnmSqY/7HMHa6kyWWSIwZt9cFvf+b+/zW7jeWQGuAN7wPs8Dvg6Nz30uOVhBGrMv7EzEmJYKRWRJ3PCLqhq7hDRfRN7BnURN9cbdAMwQke/inpY2zRt/I/CQiFyDO/P/Oq6XSmM6FGsjMCZNXhvBBFXdlu1YjDmQrGrIGGN8zkoExhjjc1YiMMYYn7NEYIwxPmeJwBhjfM4SgTHG+JwlAmOM8bn/Dy8iv0weWRKVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([Dense(12,input_shape = (4,)),Activation(\"sigmoid\"),Dense(units = 3,input_shape=(12,)),Activation(\"softmax\")])\n",
    "from keras.optimizers import SGD\n",
    "SGDoptimizer = SGD(lr = .2, momentum = .8)\n",
    "model.compile(optimizer = SGDoptimizer,loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n",
    "history = model.fit(X_train,y_train,epochs = 150, batch_size = 10,verbose = 1, validation_data = (X_test,y_test))\n",
    "plotHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a much more succesful classifier than the previous one using the adam optimizer. The accuarcy got to 100% by the first epoch and pretty much stays there. Loss also went down faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15) Remember, this is a classification problem. Use your model to predict the classes for the test data (using the function predict_classes), and store the results as y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16) Finally, using your code from the lab on classification, output the confusion_matrix and the classification_report (from scikit-learn's metric package) to print out the complete performance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0  0]\n",
      " [ 0 18  4]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      0.82      0.90        22\n",
      "           2       0.88      1.00      0.94        30\n",
      "\n",
      "    accuracy                           0.95        75\n",
      "   macro avg       0.96      0.94      0.95        75\n",
      "weighted avg       0.95      0.95      0.95        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_cat= y_test_unbinarized[\"species\"].astype('category').cat.codes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test_cat.values,y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_cat,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17) Import the above class into your code. Then write a function called create_keras_model(). Copy all of your code that creates the Sequential instance, adds the layers, activation functions, and compiles it, into this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def create_keras_model():\n",
    "    model = Sequential([Dense(12,input_shape = (4,)),Activation(\"sigmoid\"),Dense(units = 3,input_shape=(12,)),Activation(\"softmax\")])\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "# Create a wrapped keras model\n",
    "clf = KerasClassifier(build_fn=create_keras_model, verbose=1, epochs=100,batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18) At this point, you now have a classifier model that behaves like any other scikit-learn classifier! Cool, right?\n",
    "So, using the clf classifier above, use it just like you would any other classifier. Run the fit method on\n",
    "your classifier, just like you did in lab10. Use X_train and the one hot encoded y_train data. Then, use\n",
    "the predict() method to generate class predictions on X_test. Store the results in y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.9890 - accuracy: 0.4933\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.6533\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.8125 - accuracy: 0.8133\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.8400\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.8533\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.8533\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.8533\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8533\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.8533\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8800\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8800\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8933\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8933\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.9067\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.9067\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.9067\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9067\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9200\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.9200\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9200\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9200\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9200\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9200\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.9200\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9200\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9200\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 971us/step - loss: 0.2127 - accuracy: 0.9200\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9200\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9200\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9333\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9467\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9467\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9600\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9600\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9600\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9600\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9600\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9600\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9600\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9600\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9600\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9600\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9600\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9600\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9600\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9600\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9733\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9733\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9733\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9733: 0s - loss: 0.0903 - accuracy: 1.\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9733\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9733\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9733\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9733\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9867\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9867\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9867\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9867\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9867\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9867\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9867\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9867\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9867\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9867\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9867\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9867\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9867\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9867\n",
      "75/75 [==============================] - 0s 798us/step\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "y_pred  = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19) Use the predictions to generate a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0  0]\n",
      " [ 0 20  2]\n",
      " [ 0  3 27]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_cat,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20) Generate a performance report with the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.87      0.91      0.89        22\n",
      "           2       0.93      0.90      0.92        30\n",
      "\n",
      "    accuracy                           0.93        75\n",
      "   macro avg       0.93      0.94      0.93        75\n",
      "weighted avg       0.93      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_cat,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21) Now, harness the power of wrapping this class. Use your code from lab10 that performed a full cross validation. For sake of your time, you may set K to 5. Also, you will likely want to disable verbose mode for this, otherwise you'll have a LOT of output. AND, because deep learning models can take a while to train each model, it is a good idea to generate some output in your loop to show that the cross validation is progressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "df_iris = sns.load_dataset('iris')\n",
    "df_iris.species = pd.Categorical(df_iris.species)\n",
    "X = df_iris.iloc[:,:4]\n",
    "y = pd.DataFrame(df_iris.iloc[:,4])\n",
    "X = shuffle(X,random_state = 0)\n",
    "y = shuffle(y,random_state = 0)\n",
    "y_unbinarized = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           true pred\n",
       "0        setosa    0\n",
       "1        setosa    0\n",
       "2    versicolor    1\n",
       "3     virginica    2\n",
       "4    versicolor    1\n",
       "..          ...  ...\n",
       "145  versicolor    1\n",
       "146   virginica    2\n",
       "147      setosa    0\n",
       "148  versicolor    1\n",
       "149      setosa    0\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y is df_iris.iloc[:,4]\n",
    "y=pd.get_dummies(y)\n",
    "for k, (train,test) in enumerate(kfold.split(X,y)):\n",
    "    print(\"Fold: {}\".format(k))\n",
    "    clf = KerasClassifier(build_fn=create_keras_model, verbose=0, epochs=100,batch_size=1)\n",
    "    clf.fit(X.iloc[train,:],y.iloc[train])\n",
    "    df_results.append([y_unbinarized.iloc[test].values.tolist(),clf.predict(X.iloc[test,:])])\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(df_results,columns=[\"true\",\"pred\"])\n",
    "df_results[\"true\"] = df_results[\"true\"].apply(lambda x: [e[0] for e in x])\n",
    "df_def = pd.DataFrame({\"true\":df_results.explode(\"true\").iloc[:,0],\"pred\":df_results.explode(\"pred\").iloc[:,1]}).reset_index(drop = True)\n",
    "df_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true pred\n",
       "0       0    0\n",
       "1       0    0\n",
       "2       1    1\n",
       "3       2    2\n",
       "4       1    1\n",
       "..    ...  ...\n",
       "145     1    1\n",
       "146     2    2\n",
       "147     0    0\n",
       "148     1    1\n",
       "149     0    0\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_def.true = df_def.true.astype('category').cat.codes\n",
    "df_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22) Generate a full confusion matrix and final classification report based on your 5-fold cross validation of the keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def.true = pd.Categorical(df_def.true)\n",
    "df_def.pred = pd.Categorical(df_def.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df_def.true,df_def.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      0.96      0.97        50\n",
      "           2       0.96      0.98      0.97        50\n",
      "\n",
      "    accuracy                           0.98       150\n",
      "   macro avg       0.98      0.98      0.98       150\n",
      "weighted avg       0.98      0.98      0.98       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_def.true,df_def.pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
