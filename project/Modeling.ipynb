{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "For the modeling portion of this project, we will be taking a slightly different approach. In this, all years will be treated equally as separate observations. We will only be predicting Gold medal winners in select sports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will pre process our data to get just our target labels and our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/summer.csv\")\n",
    "for col in df.columns[1:]:\n",
    "    df[col] = pd.Categorical(df[col])\n",
    "df = df.drop(\"Sport\", axis = 1).drop(\"Athlete\",axis  =1)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"yearWeight\"] = (2/3)**(29 - (df[\"Year\"] - 1896)/4) # 2/3 to an exponent = to how many olympiads ago that olympiad was. so 2012's exponent is 0, 2008's is 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"medalWeight\"] = 0\n",
    "def weightMedal (row):\n",
    "    if row['Medal'] == \"Gold\" :\n",
    "        return 4\n",
    "    if row[\"Medal\"] == \"Silver\":\n",
    "        return 2\n",
    "    if row['Medal'] == \"Bronze\" :\n",
    "        return 1\n",
    "df['medalWeight'] = df.apply(lambda row: weightMedal(row), axis=1)\n",
    "df[\"Weight\"] = df['medalWeight'] * df[\"yearWeight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Year != 1896]\n",
    "allscores  = df.groupby([\"Country\",\"Event\"]).sum()[\"Weight\"]\n",
    "countries = df[\"Country\"].drop_duplicates().dropna()\n",
    "events = df[(df[\"Discipline\"] == \"Swimming\") |(df[\"Discipline\"] == \"Athletics\")].Event.drop_duplicates()\n",
    "scores = pd.DataFrame(index = events,columns = countries)\n",
    "for country in countries:\n",
    "    for event in events:\n",
    "        scores.loc[event,country] = allscores[country,event]\n",
    "for event in scores.index:\n",
    "    if scores.loc[event].count() < 20:\n",
    "        scores.drop(event,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "londonGolds = df[(df[\"Gender\"] == \"Men\") &(df[\"Medal\"] == \"Gold\") &(df[\"Year\"] == 2012) & ((df[\"Discipline\"] == \"Swimming\")|(df[\"Discipline\"] == \"Athletics\"))]\n",
    "y = londonGolds[['Event','Country']]\n",
    "scores.index = scores.index.astype(str)\n",
    "scores.columns = scores.columns.astype(str)\n",
    "Xy = pd.merge(scores, y, on= \"Event\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate our truth and our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = Xy.set_index(\"Event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.iloc[:,:-1]\n",
    "y = Xy.iloc[:,-1]\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .2, train_size = .8,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=100, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(min_samples_leaf = 5,random_state = 100)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pd.DataFrame(clf.predict(X_train),columns = [\"winner\"])\n",
    "y_pred_test = pd.DataFrame(clf.predict(X_test),columns = ['winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_f1_macro  train_f1_macro  test_accuracy  \\\n",
       "0  0.002993    0.001994       0.000000             1.0       0.000000   \n",
       "1  0.002026    0.002004       0.000000             1.0       0.000000   \n",
       "2  0.002021    0.001994       0.214286             1.0       0.333333   \n",
       "3  0.001995    0.001994       0.074074             1.0       0.166667   \n",
       "4  0.002990    0.002997       0.142857             1.0       0.200000   \n",
       "\n",
       "   train_accuracy  \n",
       "0             1.0  \n",
       "1             1.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "df_results = cross_validate(clf,X,y,cv=5,scoring=[\"f1_macro\",\"accuracy\"],return_train_score=True)\n",
    "    \n",
    "df_results = pd.DataFrame(df_results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.50      0.67      0.57         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       1.00      0.33      0.50         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.25      0.40      0.31         5\n",
      "\n",
      "    accuracy                           0.17        29\n",
      "   macro avg       0.10      0.08      0.08        29\n",
      "weighted avg       0.20      0.17      0.16        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(DecisionTreeClassifier(),X,y,cv=5)\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default decision tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.17      0.33      0.22         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       1.00      0.67      0.80         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.33      0.40      0.36         5\n",
      "\n",
      "    accuracy                           0.17        29\n",
      "   macro avg       0.08      0.08      0.08        29\n",
      "weighted avg       0.18      0.17      0.17        29\n",
      "\n",
      "Decision Tree using entropy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.50      0.50      0.50         2\n",
      "         GBR       1.00      0.33      0.50         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       0.33      0.33      0.33         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.10        29\n",
      "   macro avg       0.10      0.06      0.07        29\n",
      "weighted avg       0.17      0.10      0.12        29\n",
      "\n",
      "K neighbors=3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.00      0.00      0.00         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       1.00      1.00      1.00         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.10        29\n",
      "   macro avg       0.06      0.06      0.06        29\n",
      "weighted avg       0.10      0.10      0.10        29\n",
      "\n",
      "Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.40      0.67      0.50         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       0.60      1.00      0.75         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.30      0.60      0.40         5\n",
      "\n",
      "    accuracy                           0.28        29\n",
      "   macro avg       0.07      0.13      0.09        29\n",
      "weighted avg       0.16      0.28      0.20        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(\"Default decision tree\")\n",
    "y_pred = cross_val_predict(DecisionTreeClassifier(),X,y)\n",
    "print(classification_report(y,y_pred))\n",
    "print(\"Decision Tree using entropy\")\n",
    "y_pred = cross_val_predict(DecisionTreeClassifier(criterion = \"entropy\"),X,y)\n",
    "print(classification_report(y,y_pred))\n",
    "print(\"K neighbors=3\")\n",
    "y_pred = cross_val_predict(KNeighborsClassifier(3),X,y)\n",
    "print(classification_report(y,y_pred))\n",
    "print(\"Bayes\")\n",
    "y_pred = cross_val_predict(MultinomialNB(),X,y)\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best accuracy was find using bayes. Let's expand on that a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bayes accuracy is 27%\n",
      "lower alpha (less smoothing):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.50      0.67      0.57         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       1.00      1.00      1.00         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.25      0.50      0.33         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.28        29\n",
      "   macro avg       0.12      0.14      0.13        29\n",
      "weighted avg       0.24      0.28      0.25        29\n",
      "\n",
      "higher alpha (more smoothing):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.40      0.67      0.50         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       0.60      1.00      0.75         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.29      0.80      0.42         5\n",
      "\n",
      "    accuracy                           0.31        29\n",
      "   macro avg       0.07      0.14      0.09        29\n",
      "weighted avg       0.15      0.31      0.20        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(MultinomialNB(alpha = .25),X,y)\n",
    "print(\"Default bayes accuracy is 27%\")\n",
    "print(\"lower alpha (less smoothing):\")\n",
    "print(classification_report(y,y_pred))\n",
    "\n",
    "y_pred = cross_val_predict(MultinomialNB(alpha = 2),X,y)\n",
    "print(\"higher alpha (more smoothing):\")\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even more smoothing and a uniform prior:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.00      0.00      0.00         1\n",
      "         AUS       0.00      0.00      0.00         1\n",
      "         BAH       0.00      0.00      0.00         1\n",
      "         CHN       0.00      0.00      0.00         1\n",
      "         DOM       0.00      0.00      0.00         1\n",
      "         FRA       0.00      0.00      0.00         2\n",
      "         GBR       0.40      0.67      0.50         3\n",
      "         GER       0.00      0.00      0.00         1\n",
      "         GRN       0.00      0.00      0.00         1\n",
      "         HUN       0.00      0.00      0.00         2\n",
      "         JAM       0.60      1.00      0.75         3\n",
      "         KEN       0.00      0.00      0.00         1\n",
      "         POL       0.00      0.00      0.00         1\n",
      "         RSA       0.00      0.00      0.00         2\n",
      "         RUS       0.00      0.00      0.00         1\n",
      "         TTO       0.00      0.00      0.00         1\n",
      "         UGA       0.00      0.00      0.00         1\n",
      "         USA       0.36      1.00      0.53         5\n",
      "\n",
      "    accuracy                           0.34        29\n",
      "   macro avg       0.08      0.15      0.10        29\n",
      "weighted avg       0.17      0.34      0.22        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n",
      "C:\\Users\\Jake\\Anaconda3\\envs\\csci349\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = cross_val_predict(MultinomialNB(alpha = 3,fit_prior = False),X,y)\n",
    "print(\"even more smoothing and a uniform prior:\")\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 34% accuracy, it is not bad, considering how many options there are to choose from. We see that it is easiest to be correct when the athletics and swimming are carried by the winner, which makes sense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
